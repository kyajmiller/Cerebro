New Notes file, old Notes file died in the great Profile disappearance of July 2, 2015. RIP.

7/2 Notes:
-Compy profile died (who knows), lost old notes, new notes file now
-Hopefully Mike not too mad about losing old notes, will try to recreate notes by memory but they'll suck
-All notes from 6/12 to 7/1 are gone, pretty bad lol

So what did I do (recreation 6/22-7/1)
6/22
-Learned that unit tests should have their own separate functions, makes it easier to break them up and run one section at a time
-Added arguments to SPRF Class; wrote unit tests to make sure that GPA is passing the correct stuff when making an instance of the SPRF class
-GPA now takes more arguments
-UpdateLogicGroup function now checks for the length of the GPA results array; if more than one GPA value found, LogicGroup is set to 1; default is 0
-Added anti-context checks for GPA; unit tests for this
-Updated GPA regex
-Worked on Majors class

6/23
-Rewrote cleaning class by simplifying the regex <.*?>
-Worked on MapDBtoSPR Class (because I was really bad at understanding what Don-E intended for the class to actually do)
--Decided to go for the long haul, made a class that would connect to the database, pull out the eligibilities and scholarshippackageids,
populate respective lists, loop through eligibilities, clean each one, extract relevant information
and then return the information. It worked well enough! Worked on real world test cases too.

6/24
-Added a function to Majors, getScholarshipPackageRequirementFormat, also unit tests
-Worked on UACollege class, added more context checking
-Updated GPA regex to accept g.p.a
-Read about Flask servers, made a basic Flask server (it doesn't do much though)
-MapDBtoSPR Class now takes a SQL Query so you can specify which table and which lines to pull out instead of having a default grab
-MapDBtoSPR can now parse GPA and Majors

6/25
-Worked more on UAColleges class, updated context checking
-Added functionality to SPRF class (mostly for testing purposes, wanted a function to return a string version of the class so you could see it)
-Ran into a wall when trying to write a unit test for MapDBtoSPR Class, this is when I realized that it's probably not what Don-E wanted me to do lol
-Officially wrote the CleanText class (HTML Worker but better, I think); unit testing
-Updated CleanText functions to use re.DOTALL
-Wrote a new class that's basically a clone of MapDBtoSPR but works by reading in a text file instead of an SQL query; ScanText
-Tested ScanText on ScholarshipTest1.txt, works!
-Set default values of scholarshipPackageId in various parsers to 0
-I learned about default and optional arguments in functions! This is cool.
-Updated GPA context checker to remove 4.0 if finds '4.0 scale'
--For example, if the string is 'must have a 3.5 on a 4.0 scale' it should only return 3.5, not 3.5 and 4.0

6/26
-Ran ScanText on ScholarshipTest2 and ScholarshipTest3, works!
-Can verify that the CleanText Class works as intended, as ScholarshipTest2 was filled with html/xml tags and the cleaner worked perfectly!
-Cleaner still needs to be tested on javascript stuff
-Needed to figure out how to make Majors parser work on lists of related majors
--Example: 'systems, mining, aerospace and civil engineering' needs to return system engineering, mining engineering, aerospace engineering, and civil engineering, while the current system would only return civil engineering
--Solution: tokenize the string, grab previous five words/tokens appearing before 'engineering', concatenate each one of those with 'engineering', scan each new token with Majors parser, add the results
--NLP stuff to the rescue!
--Had to add a line of code to remove 'engineering' from the results if it didn't already exist before this loop, as it was adding it in unnecessarily
-Learned what Don-E actually intended for MapDBtoSPR class to actually do, lol
--Class is supposed to take an attributeId, access the database using a SQL Query created from that attribute Id, returns the proper regular expression from the table
--The table that the SQL Query is accessing has a row with the attributeId, regex, regexHelper, Fast Find value
--Eventually we want this class to take the attribute Id, loop through the Major Parser using the regexes on each row in the database, if a particular regex matches then return the fast find value of the major
--For now though, I will start by writing a class that takes the attribute Id and a test string, calls the database, pulls down the regex and the regexhelpers, and then returns True or False if a match is found
-Removed UpdateLogicGroup from GPA, just added in that functionality to another existing function; unit tests to reflect this

6/29
-Working on Database Helper! (the class that takes attributeID, gets regex, runs regex search, returns TF)
-Added basic functions to return first regex, first regex helper, all regexes, all regex helpers; unit tests
-Wanted to write a function that would allow you to declare whether you wanted the regex or regex helper to return True or False, but it's not working as intended

6/30
-Rewrote the True/False function, everything is working as intended but the True+True condition is broken some how by returning True no matter what, even if not True
-Ended up disabling it because it's annoying me
-Don-E took a look at the function, we decided it was overcomplicated and too long so impossible to pinpoint what exactly was broken, so I had to rewrite the function into a bunch of smaller, separate functions
--Functions called things like useOnlyFirstRegexTrueRegexHelperFalse, which checks to see if the first regex is True and the regex helper is False, and returns True if these conditions are met
--All of these work, which is a sign that smaller functions are just straight up better because things work like they're supposed to; if things aren't overcomplicated you are less likely to make errors
--I still don't know why the original one wasn't working, but okay

7/1
-Time to learn about Django - watch ALL the tutorials!
-Going to need to rewatch these again and do the exercises to follow along, because I'm realizing that I'm the sort of person where if I don't have a hands on example, the information doesn't stick
-After watching the first tutorial series, I'm bored and want to do more coding
-Learned about Selenium
--Selenium is a program that facilitates the creation of regression testing by recording what actions are taken when on a page and returns those actions in a programming format, which you can copy into your own regression test and will automate the steps you wanna take for each test
--For now, we will just be using Selenium to rip source code from the page, which will then be used for parsing out scholarship information
--Will later on use it for regression testing, as intended, but for now we don't have a web app so that's irrelevant
-Programming task: write a class that takes a URL, goes to the page, returns the page_source
--it works!; unit tests

7/2
-After compy profile died and spent several hours trying (and failing) to recover it, had to rewrite notes and try to set stuff back up
--Some of my user settings for each program are weird now, will try to fix them as they become issues later
-Going to spend rest of the work day watching more Django tutorials, will make sure to do the exercises as they come up!

7/6 Notes:
-URLs in the HTML source code seem to be reliably tagged with <a href="">, so try to make a regex:
--something like <a\shref="(.*?)"
--should make sure that the regex can span multiple lines, have seen examples where the a and href will be on different lines
--investigate this: <link href="" rel="canonical" /> maybe this is how the actual url of the page is displayed?
---This does seem to be the case, another example was <link rel='canonical' href=""/>
---In both pages I've looked at so far, there's only one instance of rel="canonical" so this seems good
---Nevermind, checked another page, didn't have this at all, might be inconsistent
--page url could also be found as <base href="">
-The page title might actually just be between <title></title> xml tags, should look at more pages to find out
--What about <meta property="og:title" or <meta property="og:description
-Description may be under <meta name="description" content=""/>
--Or <meta content="" name="description"/>

-If pulling directly from google results this will need to work differently
--each link in the results is in <a data-href=""> and the title will be between >(title)</a>
--the associated "description" for each result will be in the following <span class="st">blah</span>
--can't actually pull result links from the google source page, it don't work like that
--the source page for google only has information native to that page, the dynamic stuff doesn't exist here

-Wrote class PullPageLinkTitleDescriptionIntoArray, which does about what you'd expect it to do - it pulls the page url, title and description
from the html source code and returns an array containing those items
-The return of this class is then fed into the new class (that I also wrote) called InsertScholarshipArrayIntoDatabase, which connects to the
database and inserts the required thangs where they're supposed to be
--The unit test for this was hella tedious, do not recommend.

7/7 Notes:
-Need to build a class that access the same table as InsertScholarshipArrayIntoDatabase, which pulls out the LinkUrl, calls RipPage to get
the HTML source, and reinserts the HTML source into the LinkBody cell of the same row
-Need to finish writing last week's report for Mike
-Ran into a big issue: the CleanText/HTMLWorker classes are a little too oversimplified. They make the assumption that every page will have some sort of <html></html> and <body></body> sort of things
-The body tags wouldn't be that big of a deal if the pages weren't organized by nice div elements, but they are so fml.
-Will need to rewrite the text cleaning classes so that they actually work on stuff instead of just idealized stuff. Need to figure out a way to just get the text that actually appears on the page
-Learned that SQL is hideously picky. Doesn't like when there's single quotes in the string. Need to create functionality in CleanText that will turn all single quotes ' into '' so it doesn't make SQL mad.

7/8 Notes:
-Finish doing unit tests for PopulateEmptyLinkBodyUsingDatabaseLinkUrl
-Write new unit tests for the new functions in CleanText
-TIL: I'm not very smart
-Task for today: GoogleLeads
-New class (rewrite of PullPageLinkTitleDescriptiontoArray) GoogleLeads
--arguments: SearchTerm
--uses Selenium: goes to google, enters SearchTerm, click, blah blah
--from results page: uses xpath on each result to get link/description/title of each result
--puts link/description/title into array
--appends each of these array into a LeadResults array
--returns LeadResults
-New class: ProcessGoogleLeads
--arguments: LeadResults (from GoogleLeads)
--loops through each LeadArray in LeadResults
--calls InsertGoogleLeads
-New class: InsertGoogleLeads (rewrite of InsertScholarshipArrayIntoDatabase)
--arguments: LeadArray
--basically does the same thing that InsertScholarshipArrayIntoDatabase does, it's just called something different

-if want to be able to use Chrome driver in Selenium, need to add Chrome driver executeable to path, do it later
-Ran into an issue with GoogleLeads pulling out Titles/Links that don't have Descriptions with them, which leads to an uneven number of both lists; which in turn leads to a mismatch when trying to make the arrays
--Difficulty with figuring out how to force xpath to extract only titles/links that have a description(span) as a sibling, but it's being annoying as hell; Don-E will work on figuring out how to do this and will
get back to me on this
--Until we can fix this, implemented a check in GoogleLeads to make sure that there's an even number of titles/links/descriptions pulled out; otherwise break
--we really do need to have a way to enforce that each title/link is with its correct thing or else all hell will break loose if there's ever an instance where there's an even number of all three
but for whatever reason they're not actually all nice and associated with each other in the order that they appear in the page
-When accessing urls through Selenium, it absolutely must always have an http:// or https:// of some sort in front of it or else Selenium's gonna lose its mind. Make sure you do a check so that it will always return this cause otherwise it's bad
--Attach a http:// to all things that don't have it or else


7/9 Notes:
-So we figured out an xpath that will pull out the title, link and description of each result all grouped together, separated by newline
--Can split this string on newline, creates an array of link, title, description
--It's not as nice as the other way, as the title isn't as descriptive for some reason, but it works and is a way to enforce the correct matching
--It also only pulls out the text portion of the url and not the actual complete url. Need to append http:// to those that don't have it already attached at the front or else Selenium won't work
---Need to test if this is an issue with the normal links pulled out.
--Sometimes it doesn't pull out a title at all. fml. Need to add a check so that if it pulls out three elements, element[1] is the title, and if only two elements then there is no title and element[1] is the description
-Just realized that the xpath I was using to pull out the array of links isn't actually returning any links, just link titles, need to fix this asap
--So I found the xpath that gets the link, but it's an attribute and not an element itself, which is making selenium unhappy; need to figure out how to use selenium to pick out attributes
--Fixed it! Change the arrayOfTitles to the xpath originally used for arrayOfLinks, run a loop over each element in arrayOfTitles, element.get_attribute('href'), append that to the new arrayOfLinks, yay
-GoogleLeads seems relatively finished now, will probably encounter some more problems but don't worry about it for now

-Start work on ProcessGoogleLeads
--ProcessGoogleLeads was ridiculously easy? It's four lines... need unit testing
--I really don't want to do unit testing on an database thing with no way to actually delete what I'm going to be putting in there
--Might make a copy of the hrefs database for testing purposes, make an optional argument so I can specify that I want to use the testing databse but otherwise have it do the actual one by default so I don't end up having to change too much of it later.
-Need to make an equivalent of PopulateEmptyLinkBodyUsingDatabaseLinkUrl for the dbo.GoogleLeads
--Wrote class GoogleLeadsUpdateEmptyLinkBody, unit tests, works perfectly

-In the meantime, Don-E wants me to make something similiar to the GoogleLeads classes but that can run on scholarship search sites/scholarship pages


7/10 Notes:
-Try a test on GoogleLeads, let's see what happens
--Both ProcessGoogleLeads and GoogleLeadsUpdateEmptyLinkbody work perfectly!
---need to figure out a reliable tear-down method for the unit test, because you can't just run the unit test willnilly or else there's going to be a crap ton of duplicates
-Make the GoogleLeads-esque thing that works on other websites. Needs to do relatively the same thing (get results, get the links + titles+ descriptions, store stuff, update database with page stuff)
-Need to add functionality to GoogleLeads to be able to go to multiple results pages
--Two options for this:
--Can either use a while loop with an incrementing value and have a driver command like driver.find_element_by_link_text("7").click()
---This one might be a little more complicated to implement but could work on websites other than just google. Hopefully on other searchy websites they don't have links with number text outside of their search results stuff
--Or use a command that just clicks the next button driver.find_element_by_xpath("//a[@id='pnnext']/span[2]").click()
---This one slightly more simple (no loops needed for incrementation), but will be specific to google
--Either one will need a check to make sure the link actually exists so that it doesn't break the program with an icky error message.
---Use find_elements to do this, will return an empty list if it doesn't find anything, check if find_elements = [], if not then go
--Put a limit on how many next pages it goes to (10)

So far, something like this doesn't work for some reason. It's kind of icky.
currentPage = 1
    while currentPage <= 10:
        self.getGoogleLeadsArrays()
        if self.checkIfNextPage() == True:
            self.goToNextPage()
            currentPage += 1
-It's giving an error when trying to find the href attribute of the links that 'element not found in the cache'
-changing the list name doesn't help, omg
-Don-E fixed it lol.
--Workaround = once at next page, store the current url, close the current driver, open a new driver, make it go to that url, ???, profit
-So we pissed off google. Google doesn't like being searched via bots. fml.
-IP spoofing?

-Other than that, the google thing appears to be pretty much finished. There might be an issue with the insertion method but I really can't test it like this
-things to do on monday: make the non google version of the googleleads thing. Would start it now but I'm tired and this is hard

7/13 Notes:
-Try to find a work around for whatever's making Google mad with the old thing.
--I honestly think that what's flagging Google is the blatantly non-human behavior of the driver. Real people don't access a results page of google by using a url that takes them to the exact page of some exact search term.
--Real people go to google, send their search query, and in the case they want to go to some exact page they click the page number at the bottom of the results page
--So either find a way to make it work by keeping everything all in the same driver window and just have it click next (the most humanish option), or if you absolutely have to have multiple driver windows, have it repeat the steps (go to google, send keys, etc) everytime.
--Second option might not work still as it is still multiple browser windows accessing multiple results pages, but it is still less weird than what it's currently doing.
-Explicit waits don't work for this because if you do something like waiting until it locates the element to proceed, it gets really angry if there's more than one element in the xpath, which is really really stupid

-Got it to work without having to declare multiple browser windows! Ended up making it have to go back to the default page and then reaccess the results page. It's weird but okay
--For some fucking reason it's really weird about how it wants to do these things.
--Can't just have it go back to the default page, send the keys, and then click the link number. It doesn't like this.
--What it does like is from current page, go to next page, compare urls (???) if they're different, then go back to default page, send keys, wait a bit, click the next button, wait a bit
---I have no idea how I would make this loop properly but fuuuuuuck
---If I legit will have to keep a counter to make it click next a certain number of times to access each next page of results, I guess it would work, but it would be slow as hell
----Okay, you can't make it click the next button multiple times, it doesn't like that
-------GOOGLE WHY
-------WHY ARE YOU SO WEIRD I DON'T LIKE THIS WTF
-I give up. It goes to page two. We don't need page 3-10. People don't usually care about stuff after page two anyway.
-At the very least, this shouldn't make google freak out about weird activity because it's only accessing two pages at a time instead of ten, which is good. If they still have a problem with it it's because they're ridiculously anal.

-No more work on GoogleLeads. It's done, I'm satisfied with it. Finally start working on the non-Google thing.

-First Website to work with: Pivot
-Need to make an account (will have to have the program log into the account, so make a default one that doesn't care about anything)
--Or maybe not? just access via http://pivot.cos.com/funding_main
-The xpath to grab each of the results on the page: "//a[@class = 'pivot_track_link results-title-link']"
--link = href, title = text
-Steps:
    go to page, enter keys, go
    grab all of the results on the page, put in array (link + title)
        maybe repeat for a couple of results pages, for now just stick with one
    for each link/title given, go into the link, grab the website url ("//a[@title = 'Web page opens in new window']").href
    need to figure out how to grab the abstract text, doesn't really have a distinct xpath so it might be weird

-NVM: Do GrantForward instead of Pivot. Basically do the same stuff
-https://www.grantforward.com/index
-grab results using ("//a[@class = 'grant-url']")
-Title = .text
-Results Link = .href
-grab results description using ("//div[@class = 'description']")
-match them together
-then go into the results link, get the website of the grant using ("//a[@class = 'source-link btn btn-warning']") .href

7/14 Notes:
-Continue working on GrantForwardLeads
-Need to verify that GrantForwardLeads should just pull out the exact same stuff as GoogleLeads or if Don-E wants more stuff extracted
-Wrote unit test to verify that GrantForwardLeads works, pulls out the title, description and source website link
-Now work on a way to get it to go to the next page of results and pull out the resultspagesarrays for those too
-The original way that selenium chose to access the Next button on the pages isn't compatible with my python interpreter (because the Next button contains a unicode item that it really doesn't like)
-New way to access the Next button: "(//a[contains(text(), 'Next')])[1]"
-The next page button works perfectly well. It's too bad Google couldn't have worked so nicely. Time to make a loop for this.
--The loop works, need to put a limit on how many next pages it'll go to; limited it to pull only the first ten pages.
-GrantForwardLeads is done, just waiting for Don-E to make the database and then I can write the code to put the stuff in the database

-Don-E wants the following things pulled from GrantForward:
    keyword (presumably the search query used)
    url (the link to the result page on the grant forward website)
    name
    description - ("//div[@id = 'field-description']/div[@class = 'content-collapsed']") textContent
    sponsor - ("//div[@class = 'sponsor-content']/div/a") text
    amount - ("//div[@id = 'field-amount_info']/div[@class = 'content-collapsed']") textContent
    eligibility - ("//div[@id = 'field-eligibility']/div[@class = 'content-collapsed']") textContent
    submission info - ("//div[@id = 'field-submission_info']/div[@class = 'content-collapsed']") textContent
    categories - ("//div[@id = 'field-subjects']/ul") textContent
    opportunity source link (the website link)
    opportunity source text (the text from the website link)
-so more things to extract, more things to do with GrantForwardLeads
-ultimately, I want the GrantForwardLeads to return an array in the following format:
[keyword, url, name, description, sponsor, amount, eligibility, submissioninfo, categories, opportunitysourcelink, opportunitysourcetext]
-need to make checks for each element on the page, chances are they might not exist for that particular page
-GrantForwardLeads appears to be mostly finished for the time being, it loops through the results and gets the stuff
-Wanted to put the rip page functionality in GrantForwardLeads so that I wouldn't have to make another class to populate it later, but it's being weird for some reason

7/15 Notes:
-GrantForwardLeads and its associated classes (InsertGrantForwardLeadsBlah and ProcessGrantForwardLeads) are finished!
--something unresolved: removing non-unicode stuff from the ripped page. Needs to be fixed eventually. For now it's whatever. Just don't try to print the ripped page to console.
--Also: for the insert function, need to do a check against existing items in the database - if an item already exists with the same keyword/url as the current item, don't put it in!
-New programming task: make a class that goes through the majors database, pulls out each major, then feeds it into GrantForwardLeads (big loop)
-Class 1: GetFastFindMajorsList
--Go to database, use sql query to get majors, put majors in a list, return the list
--Done, unit test works, yay
Class 2: RunMajorsListOnGrantForward
--take majors list, for each major in list, call ProcessGrantForwardLeads (which does the stuff)

7/16 Notes:
-Start working on GrantForwardRunMajorsList
--Running tests, takes ages, I set it to only loop over the first five items on the majors list, but that's still like 500 grants
--Did a test run of GrantForwardRunMajorsList, it works as intended

-Recreate this system for Pivot too now.
--Copy of previous notes on Pivot:
-First Website to work with: Pivot
-Need to make an account (will have to have the program log into the account, so make a default one that doesn't care about anything)
--Or maybe not? just access via http://pivot.cos.com/funding_main
-The xpath to grab each of the results on the page: "//a[@class = 'pivot_track_link results-title-link']"
--link = href, title = text
-Steps:
    go to page, enter keys, go
    grab all of the results on the page, put in array (link + title)
        maybe repeat for a couple of results pages, for now just stick with one
    for each link/title given, go into the link, grab the website url ("//a[@title = 'Web page opens in new window']").href
    need to figure out how to grab the abstract text, doesn't really have a distinct xpath so it might be weird

-I really hate pivot for deciding to give all of the structures on their pages generic names that I can't reliably use to pull out content. fml
-I can easily say that after doing this internship I am very experienced with using xpath.

xpaths for information:
-Source website = "//a[@title = 'Web page opens in new window']" .textContent
-Sponsor = "//div[@class = 'span2']/span[text() = 'Sponsor']/../../div[@class = 'span6']" .textContent
-Amount = "//div[@class = 'span2']/span[text() = 'Amount']/../../div[@class = 'span6']" .textContent
-ApplicantType = "//div[@class = 'span2']/span[text() = 'Applicant Type']/../../div[@class = 'span5']" .textContent
-CitizenshipResidency = "//div[@class = 'span2']/span[text() = 'Citizenship or Residency']/../../div[@class = 'span6']" .textContent
-ActivityLocation = "//div[@class = 'span2']/span[text() = 'Activity location']/../../div[@class = 'span6']" .textContent
-Abstract = "//div[@class = 'span2']/span[text() = 'Abstract']/../../div[@class = 'span6']" .textContent
-Eligibility = "//div[@class = 'span2']/span[text() = 'Eligibility']/../../div[@class = 'span6']" .textContent
-Categories = "//div[@class = 'span2']/span[text() = 'Keywords']/../../div[@class = 'span6']" .textContent

-For some reason, one of the websites is forcing firefox to open in safemode, which makes my unit tests not work...

7/17 Notes:
-Set GrantForwardRunMajorsList to run over night, it didn't get very far, was killed by page timeout
--Need a way to get around this sort of thing, so that if one page doesn't work, it'll skip that whole thing and just go on to the next one
--Maybe use a try/except statement
---This seems to have worked, as current tests have been able to past the point where it broke previously
-Hopefully, unless the internet goes down over the weekend, it should have no problem running. It will probably take a couple of days to get through the entire list, as I've already run it for almost six hours and it's still not out of the A's yet
-Need to fix the GetFastFindMajorsList so that it checks against what's currently in the GrantForwardItems keywords
--tested it, for some reason it only removes the very first item and puts it on the back of the list
--not sure if it's because the keyword got distorted somehow, when being inserted into the database, but who knows

-Potential issue with the GrantForwardLeads - we want to avoid adding duplicates to the system - right now it checks if the same URL exists under the same keyword
-but the same scholarship(same id) might get in there twice if it has a slightly different url; don't know if there's someway to extract the grant-id other than by extracting it from the url
-might need to do this though.

7/20 Notes:
-Need to type up report for Mike
-Program pretty much ran for ~36 hours before dying this time (only died because lost connection to the SQL database). This is pretty much successful. Will run it again later when leave for the night.
--Perhaps see if there's a way to keep the SQL connection open constantly to avoid that happening again.
--Is there a way to pause running a program in pycharm? I'm sure if this program keeps running over night it'll still be running when I come in tomorrow, and I don't want to have to completely kill it in order to be able to use my computer.

-Continue working on Pivot today.
-Talk to Ken about staying on longer.
-Write a script to fix spacing in the database.

-Pivot unit test works, seems to have solved the starting Firefox in safemode thing.
-Wrote the process pivot leads
-Wrote InsertPivotLeadsintopivotleadsdb
-Wrote appropriate unit tests
-updated get fast find majors list to have separate functions for each list type I want
-wrote the code to automate the system as it runs over the list of majors
-doing the test run
-make sure get back thing from emily

7/21 Notes:
-Is there a way to save the progress of a program? I dislike having to completely kill the program every time I want to actually use my computer
-Pivot program runs perfectly fine so long as you don't accidentally hit the shift key and send firefox into safe mode, was still running when I got here today

-So Pivot and GrantForward scraping programs are pretty much done, everyone is happy
-Ken wants each thing to be labeled by what it actually is (scholarship, fellowship, grant, research funding, etc etc)
--Need to build a classifier to do these things

-Step 1: Training data
--Need to build training set
--How big is enough?
--How to tag the training set
--What do use as the training set? Perhaps the descriptions/abstract
--Is there any information that I can pull from the pages that will give me further info?

Step 2: Feature Selection
-Want at least unigrams and bigrams

Step 3: Build classifier
-Can probably use scikit learn toolkit
-Either NB or Perceptron, see which one gives better results on the training

Step 4: Train the classifier
-How do you save training info? I don't want to have to train the classifier every time it needs to run, that's kind of ridiculous
-What's a good accuracy threshold? Should be at least 75% if possible

Step 5: Classify stuff
-How to save results? Perhaps stick them in the database somewhere when done
-I'll need a bigger labeled set so I can have labeled testing to check my results on

My life just got harder

So, before I can start tagging the training set, I need to figure out what the tags should be
-What are the most common terms found in my training data? Maybe that will give me insight
--Training data: use abstract + eligibility info
Steps:
1. Connect to database, get rows from PivotTags, get Eligibility and Abstract, concatenate, append concatenated item to list, return list of items
2. Class to run loop over each item in list, feed into Tokenize, get unigrams and bigrams, then combine all of them into one massive list
3. Tokenize will tokenize on whitespace and punctuation, return list of unigrams, bigrams
3.1 Might want to filter out stop words
4. Use FreqDist.most_common from nltk to get most common items

-need to set up taskmanager to run stuff automatically
-tomorrow will really need to set up a stopword filter, current tests of MostCommon are basically just nothing but stopwords
-also need to filter capitalization


7/22 Notes:
-start working on implementing stop words and capitalization filter for Tokenize
-once finished, rerun the test, see what the words are
-research popular scholarship types

-finished implementing the capitalization filter and the stopwords list, not really sure what labels I should use though
-obvious labels (from the results): research, grant, fellowship, scholarship, internship
-Okay, from the looks of it (and the small amount of labeling I've done so far), these scholarship things tend to state pretty blatantly what they are in either the title or description
-Will label all 500 in this database then figure out what to do
-Will probably not build a machine learning classifier as it looks to be really unnecessary, will probably go with a lexicon based classifier which is a lot more simple
--Scan title for keywords, if keyword in title, then label; if not, scan abstract, then scan eligibility
--Some label keywords have more weight than others. If something is called a 'research fellowship' it should be labeled a fellowship over research
--Scholarship > Fellowship > Grant > Research > Award
--Might do a count feature
-ugh though. What do do about 'research grant' - it's a grant, but it's research; just call it grant, cause it's technically a grant


7/23 Notes:
-finished labeling the 500 test cases
-updated GetPivotTagsTitleAbstractEligibility to return not just a concatenated string of the title, abstract, and eligibility, but also them in a tuple if desired
-time to work on the classifier
--stuff has been tagged, and the tokenizer class pretty much does all the feature selection I want for the classifier, will add features to count keywords
--might not even need the bigrams
--run a search over the unigrams, if see 'scholarship' then it's a scholarship, if see fellowship then fellowship, if see grant then grant, etc
-I want the classifier to be able to run over other stuff besides just this test, so have it import the data

Steps:
-Import the data = string (concatenated title, abstract, eligibility)
--would import the tag, but the whole point is to assign tags to the strings, so outside of these first few tests cases there won't be a tag
--will make another class that compares the assigned tag to the actual tag for this test case

-get the unigrams

-declare the counters for the tags: scholarship, fellowship, internship, grant, research
-scan the unigrams:
--if scholarship in unigrams, tag = scholarship
--elif fellowship/fellow in unigrams, tag = fellowship
--elif internship/intern in unigrams, tag = internship
--elif grant in unigrams, tag = grant
--elif award/prize in unigrams, tag = award
--elif research in unigrams, tag = research
--else, tag = other
-append the tag to list

-then, check list of predicted tags versus list of actual tags
--calculate accuracy, precision, recall, f1

7/24 Notes:
-So I got banned from Pivot. Lol.
-Don-E satisfied with the direction of the fundingtypes classifier
-Today test and tune funding types classifier, see how accurate it is
-Want to be able to pull out deadlines for scholarships
-Wrote a unit test to see if the ClassifyFundingTypeKeywordBased works, it does work on the dummy tests
--just not sure if it's working on the actual thing, might be taking forever because it's so big
-Finally tested the Keyword Classifier (it had problems, I accidentally wrote a neverending loop)
--Has a 73% accuracy rating
--That's not terrible, but ehhhhhh
-So, comparing the predicted tags against the actual tags, some trends:
--Fellowship is pretty much perfect, only ones that aren't correctly tagged are tagged as scholarships
--Scholarships tags overzealously, but all of the scholarships are correctly tagged except for one listed as Grant
--Internships needs to be ranked higher over fellowships, otherwise good. One incorrectly labeled as Award because called apprenticeship
-Some of the mismatches are my error in tagging
--Need a way to force it to check title over abstract/eligibility for scholarship/fellowship/internship/grant

7/27 Notes:
-More work on the classifier
-Need to make it work such that it checks the title before checking the abstract, if finds keyword in title then that's it
--Will probably make the program feed in the title and abstract+eligibility separately and then write a heirarchy based on that
-Conflicting keyword existence
--This is the one issue where doing a lexicon based tagging works really poorly. The tagger picks up on any instance of the keyword regardless of context
--Could do bigrams but in order for it to work properly I would have to keep in stopwords, which could be weird. Even then, this would be irrelevant for a keyword search
--Fix heirarchy, maybe add in particular words to the keywords list, and then maybe be prepared to not have completely perfect accuracy
-Might need to not even look at the eligibility information at all for this classifier, as there might be conflicting information
--Might mention that you can't be receiving a different grant, which doesn't help
--Rarely they might mention that the award is a grant in the eligibility; might need to make a counter for keywords if have to search the eligibility, or just don't search it at all... ugh
-After having fixed my mistakes in tagging, and reworking the classifier to run over just the title and abstract (separately), and rearranged the heirarchy, brought up accuracy to 94.8%
-Time to run the classifier over the entirety of PivotLeads
-Wrote class of staticmethods to get information from PivotLeads (title, abstract, eligibility, pivotLeadsId)
-Wrote the script to run the classifier over the pivot leads rows, loops through each keyword in the database and stores the associated tags
--Didn't want to make the program have to store 19k tags at once, sounds mean
---It actually runs really quickly
-Added 'studies' to researchKeywords, brought up accuracy to 95.4%, I'm really satisfied with this

7/28 Notes:
-New task: write a program that scans through each row of PivotLeads (where Tag='Scholarship'),
--extracts the abstract/eligibility, scans through with parsers, and returns the GPA, Due Date, and Major
--inserts the GPA, due date and major into PivotLeadRequirements, also the PivotLeadId from the PivotLeads table
---when doing the insert, for each value pulled out insert new row: AttributeId, AttributeValue
--Make sure the program can take a list of values to run
-Converted PivotLeadsGetDatabaseInfo from a bunch of static methods to a normal class that takes a keyword and an optional tag value
-fuck my life. I wish I would have thought to have pulled out the due dates for these scholarships on the nicely formatted pivot page before getting banned from pivot. Would have been infinitely more convenient than having to attempt a regex search

Due date context keywords:
-due date
-application window
-close
-deadline
-close date

-need to figure out a good regex to get dates
((January|February|March|April|May|June|July|August|September|October|November|December)|([01][0-9]\/))(\s[123]?[0-9](st|nd|rd|th)?[,\/]?(\d{2})?\s)?(\d{4})?
this one should work for dates formatted either like January 15 2015, January 15, 2015, January 2015, 01/15/2015
hopefully I don't get any weird date formats popping out
-The regex is being weird. It's interpreting the parentheses in the regex as separate groups when I want the whole thing to be a single group. Have to figure out how to fix this
--Putting a parentheses around the whole thing does work to make it capture the entire date as a single group, but it still also returns the individual groups
--I could limit it by making it only return the very first result, but how can I be sure that the first result is the full one (it could be something else for all I know)
--How to force greedy matching python

7/29 Notes:
-Need to work more on the dates regex
--might need to just have multiple different regex for the different formats instead of just one big one...
Month + year: (January|February|March|April|May|June|July|August|September|October|November|December)\s\d{4}
Month + day + year : (January|February|March|April|May|June|July|August|September|October|November|December)\s[0-3]?[0-9],?\s\d{4}
mm/dd/yyyy: [01][0-9]\/[0-3][0-9]\/[12]\d{3}
Month + day (not perfect): (January|February|March|April|May|June|July|August|September|October|November|December)\s[0-3]?[0-9][^\d]
-rewrote the DueDate class so that instead of relying on Parser it functions independently.
-The issue before was in the differences between how re.search and re.findall work. Re.search will greedy match the regex, and return the greediest match as the group.
--Re.findall will return all the capture groups as their own result
--So what I needed was re.search; Parser uses re.findall, so it was easier to just write small functions that use re.search for DueDate
-Works as intended now
-Updated PopulatePivotLeadRequirements so that it now gets both due date and GPA; due date and GPA have separate functions
--Having separate functions will make it a lot easier if Don-E wants me to update the class to extract more things
-Updated DueDate to format the dates it extracts into a nice, consistent format
-Not going to try running the program until tomorrow because not sure how Don-E wants to feed it the major lists

7/30 Notes:
-PopulatePivotLeadRequirements needs a helper class that gets the listOfMajors and feeds it into PopulatePivotLeadsRequirements.
--Can use the PivotLeadsGetDatabaseInfo to get the list of existing keywords with the scholarship tag
-Issues with Inserting DueDates into the PivotLeads table - needs a single date
--So when the parser is pulling out more than one date, it needs to make a decision for which one to keep
---One immediate issue is that the source text is weird as hell, makes the sentence parser unhappy; need to limit sentence searching for sentences with less than a certain amount of characters in order to avoid pulling out dates from non-sentences
--Either make a static upper limit on sentence character length, or have the function compute an average to go on
--Setting it to 1000 upper limit (which is ridiculous) seems to be okay
---What to do about sentences such as the following:
'The scholarship deadline dates for academic year September 2016-May 2017 are : January 15, 2016 '
---I don't want it to pull out the academic year thing
---Might need to make a priority system: the most specific date wins out
---Something like MDY > MY

-So the PopulatePivotLeadsRequirements works fine
-Now basically do the same process for GrantForwardItems:
--Step 1: Tag grant forward items (copy PivotLeadsRunFundingClassifier, PivotLeadsGetDatabaseInfo)
--Step 2: PopulateGrantForwardLeadsRequirements (copy PopulatePivotLeadsRequirements)

-deleted a couple of unnecessary functions from PivotLeadsGetDatabaseInfo, also fixed some stuff in its dependencies
-Rewriting code is tedious

7/31 Notes:
-Need to make a RunPopulatePivotLeadRequirementsOverMajorsList equivalent for GrantForwardRequirements
-Need to make an executeable file that takes a command line argument (so you can run it in task scheduler)
--I have no idea how to do this and it's frustrating
-Figured it out, use sys, set the argument you want to pass as sys.argv[1], then call the class and pass the argument to it
-running the programs through the command line does not support the use of Path.Path.Whatever so had to get rid of the path stuff. Make sure everything lives in the same directory
-Now just need to figure out how to run it through the task scheduler, should be okay
-Okay it works, yay
-Turns out we don't want it to take a number of majors, but a list of majors
--This is hard, the commandline sucks balls
--Command line arguments wants to import everything as a string, which works okay for 'All' but not so much for a list of things
---fml
-Need to figure out how to make the program read everything in that isn't 'All' as a list
-Oh for fuck's sake
-I really really hate the command line
--Like forreal
-Found a way to make it accept things with spaces as all one argument, as well as lists: use ast
--Pros: If you type in a list like this "['list1', 'list2', 'list3']" it works nicely, and then you can have your list, which is great
--Cons: It's really really obnoxious if you want to do anything besides lists though. No single strings. If you want a single string, put it in the list "['happy string']" and then parse the list
--Pros: It does allow you to get in single strings like East Asian Studies in that obnoxious way, which wouldn't be possible otherwise
-Turns out one of the major issues I was having with getting the thing to loop across the list is that when you set a default value to something, it enforces that whatever goes in is a of the type of the default value
-Since the damn function needs to have something to run over, just make it be a normal value, then you can set it to whatever you want

-Start working on dynamic sql query function. This is a lot more annoying than I thought it would be. I'm going home.

8/3 Notes:
-Moved compy, it's weird, whatever

Stuff to do today:
-Write up report for Mike
-Work on dynamic sql query function - I have ideas for how to make this work!
--This is finished, converted the column names to a simple string using join, converted the insert values to a format with '' around them, then joined those together
--Rest was just string interpolation
-See what Don-E wants me to do after that
-Pick a website, basically do the same thing as for Pivot/GF
-Began work on Scholarsite
--the layout is really different from Pivot/GrantForward, such that there's no real search function
--Everything is labeled by the institution that the scholarship can be applied to, so will only grab results that are related to the UA
---Other than that there's no way to filter out by majors, so will just grab everything that has the UA tag
--It's really strange. There's no individual page for each scholarship, clicking on one just opens a widget with the relevant information
---Really annoying to get the info this way but whatever. It's doable.
--Many of these have fuck all in the ways of actual information for the scholarship. Not fun. Not even a source website for the scholarship. Ugh.
---Most don't even have deadlines
--Luckily there's only 95 results for the UA, so it'll just be done and done. Can do whatever with them after grabbing them

8/4 Notes:
-Continue working on ScholarsiteLeads
-Finished ScholarsiteLeads class, returns the array of all the University of Arizona tagged scholarships, yay
-Made ScholarsiteLeads table in database
-Wrote unit tests for ScholarsiteLeads

-Looked at some more sites on the list, most are garbage

-Being work on Fatomei
-Because of how weird the site is laid out (the whole thing is just a simple table, no real heirarchy to it) it will be pretty much impossible
-to group the scholarships based on the sponsor like they are on the site. Will just ignore the sponsor thing.
--Titles + websites: "//td[@class='a']/a"
---.href to get links
--Descriptions + DueDates = "//tr/td[@class='f']/../td"
---Even indexes = dates (use if i % 2 == 0 to check if even); odd indexes = descriptions

8/5 Notes:
-So for some reason the server really doesn't like me. Likes to randomly delete my server credentials. Luckily this time it was easily recoverable but it's annoying
-Continue working on Fatomei Leads
-After fixing a bunch of bugs with the InsertFatomeiLeadsIntoFatomeiLeadsDB insert statement, Fatomei has been crawled.
--Need to run the classifier over FatomeiLeads (RunFundingClassifierOnFatomeiLeads)
--Wrote the FatomeiLeadsGetDatabaseInfo class
-Adding 'extern', 'externship' to Internship keywords for funding classifier
-Need to build FatomeiLeadsRequirements table and associated class
--Not sure how well this is going to work because there's really no info in a lot of the descriptions pulled from the site and
the source website isn't always the most reliable. Fatomei isn't that great of a site to scrape. Will set this up now and then just not worry about it
-Will set up the parsers to run over both the description given and over the source website text
-Need to get the other pages of Fatomei site too, this site is set up so weird that I didn't notice them...
-luckily easy way to grab all the extra page links, so problem largely solved

8/6 Notes:
-continue testing fatomei leads
-added a check to make sure the clicky thing actually exists
-figured out why my loop over the other pages wasn't working, so trying to run the whole thing forreal now
-For some reason, it really hates the women scholarships page. The go to other pages thing works fine during tests of just that function, but -
--nvm I think I know what's going on; there's not the same number of dates as there are entries? which is weird because they should all have the same things, even if there's no date in the box...
--yeah there's 79 dates and 80 titles on the page, it's stupid; not sure how to get around this
--One of the titles is missing a description row, which is what's messing it up... not sure if I can just skip this one, or just delete it somehow
---Is there a way to check for very following sibling?
---Use immediately preceding sibling in order to get a classes whose immediate next sibling is class f, will only grab those that have an f element following them
-Today is just not my day to actually try and do any work. Forreal

8/7 Notes:
-Fatomei Leads finally worked, everything is in the database, yay
--I probably didn't format the table correctly when setting the identities because the FatomeiLeadsIds are kinda weird, but
so long as they're unique it's not that big of a deal. They're just weird.
-Need to run classifier over the new stuff in the database - done
-Now can work on PopulateFatomeiLeadsRequirements
--This one will be different than the other Populate classes, because in order to get the majors I'll actually have to parse them out of the text...
--Need to update the majors parser, use GetFastFindMajorsList to know what to search for
---nvm, don't really need to change Majors at all, just need to make a function in Populate, call FastFindMajors to get the list, put everything in lower case, then feed it and the string into Majors
-So I ran PopulateFatomeiLeadRequirements, but nothing happened. I'm not sure if I wrote this wrong, or if in the entirety of 334 scholarships tagged as a scholarship not a single one has GPA/Major info. Seems unlikely
-Seems there's something seriously wrong with the Populate class because I can't even import it into the unit test without it throwing errors (I'm not even *using* the import statement, which is fucking weird)
-The problem seems to lie in using the FastFindMajorsList to make the majors regex because the normal TestMajors unit test seems to work okay (with the majors regex that one uses), so there's something wrong with the fast find majors list
-I'm just really not sure *what* that could be. It returns a list of majors in strings. So unless there's something weird about those strings it should be okay.
-The FastFindMajorsRegex creates an issue with what it's returning from the re.search. Should try removing all of the things in the list that have parentheses, that's probably creating capture groups, resulting in tuples instead of strings
--Removing the parentheses seems to have fixed it; not sure why the runtime is so long but okay
-And now that the majors thing is fixed, now the entire program works. Yaaaaaaaaaaaaaaaaaaaaay
--Having those parentheses in the FastFindMajors list is really really obnoxious, should probably just remove them completely when calling it instead of having to do it later...

-Start working on CollegeGreenLight, basically do the same thing all over again. Yay.
-This one might work strangely because it has a log in to deal with, but it should be okayish

8/10 Notes:
-Finish CollegeGreenLightLeads, write InsertCollegeGreenLightLeadsIntoDB
--need to make the associated table, needs columns CollegeGreenLightLeadId, Name, Amount, Deadline, Sponsor, Description, Requirements, Url, SourceWebsite, SourceText
-Need to create PopulateCollegeGreenLightRequirements, needs CollegeGreenLightGetDatabaseInfo
--Luckily don't need to run the classifier over the CollegeGreenLight stuff, everything pulled out is a scholarship anyway...
--May eventually fix the collegeGreenLight crawler to change settings on its own and try to get more things, but not sure if it would really make a difference; also, how to know what combinations to set? seems like a bit much
-CollegeGreenLight stuff is pretty much done now
-Now working on Unigo

-Unigo sucks. Weird site. First time selenium has completely failed me. oh my god.
-Grab all of the scholarship results objects = "//div[@class='scholarshipWrap']"
--nvm this dies the second you start clicking them, need someway to get the results urls
--Clickable object: "//a[@data-bind='click: function(scholarship, event) { $parent.showScholarshipDetail(scholarship, event) }']"
--There's no way to get the href to the results page, which is really stupid... having to click through each one isn't going to work
--I"m pretty sure if I click, grab stuff, hit the back button, and then reexpand all of the see more things it's going to trigger some sort of bot detection... I really don't see why there's no way to just grab the url of the damn result page
--The object has an href, but it just takes you back to the same page you're already on... this is dumb
-Amounts: "//div[@class='amount']/span[@data-bind='text: Aequitas.toCurrency(DollarAmount)']"
-Titles: "//h4[@data-bind='text: $parent.resultLayout ? shortTitle : Title']"
-Deadlines: "//h4[@data-bind='text: $parent.resultLayout ? shortTitle : Title']"
-SourceWebsite button = "//a[@class='button secondary']" .href
-Sponsor: "//div/p/strong[text() = 'Awarded By']/../../following-sibling::div/p" .textContent
-AwardAmount: "//div/p/strong[text() = 'Awarded By']/../../following-sibling::div/p" .textContent
-Recipients: "//div/p/strong[text() = 'Recipients']/../../following-sibling::div/p" .textContent
-Requirements: "//div/p/strong[text() = 'Requirements']/../../following-sibling::div" .textContent
-AdditionalInfo: "//div/p/strong[text() = 'Additional Information']/../../following-sibling::div/p" .textContent
-Contact: "//div/p/strong[text() = 'Contact']/../../following-sibling::div/p" .textContent
-Address: "//div/p/strong[text() = 'Address']/../../following-sibling::div" .textContent

-For the things on the results page, they don't have their own descriptive xpath, may have to use siblings
--text() = 'Sponsor'

-So far, unigoLeads seems like it works, haven't tested a full run yet but I want to be able to start storing stuff if I can get the table made and the process/insert classes done

8/11 Notes:
-Unigo leads is really fussy. Sometimes it has no problem locating elements, and other times it's unhappy. Seems to be related to the speed at which the page loads
-Will attempt to add in explicit waits to see if that will help
-I"m not very smart, accidentally had the same xpath for both the sponsor and the award amount, need to fix it
-UnigoLeads finally ran through, put all the things in the database, yay
-Need to add Tag column to the table, set all of them to 'Scholarhip', then write the Populate class and the GetInfo class
-I realized that all of my Populate classes basically recycle the exact same functions except for one, so I made a PopulateRequirements super class
--Currently in the process of converting all of them over to use the super class, it's very spiffy
-Unigo finished, ran current iteration of Populate over the scholarships, think I will need to eventually update populate to try grabbing more stuff besides just gpa and major

-Begin work on IefaLeads
-Next page button: "//ul[@id='yw0']/li[@class='next']/a"
--Nvm, this doesn't work cause it's not clickable, better to just use findElementByLinkText('Next >')
-Not really sure how I want to do this because there's nearly 1200 items to pull, I don't really want to have the program store 1200 things because I'm not sure if it can
-Will try it, if it dies then will figure out if I can loop through it and pull one page at a time
-Process the featured/not featured rows separately because different xpaths, just do the featured ones first
Normal:
-title/link - "//tbody/tr[not (@class='featured')]/td[@width='200px']/a" .href(link), .text(title)
-majors - "//tbody/tr[not (@class='featured')]/td[@style='width: 95px']" .textContent
-description - "//tbody/tr[not (@class='featured')]/td[3]" .textContent
---Make sure to filter out the Nationality and Host Countries lines, could do a regex replace like re.sub('Nationality:*.$', '', string)
-Nationality - "//tbody/tr[not (@class='featured')]/td[3]/p[@class='award-list-nationality']" .textContent
-Host Countries - "//tbody/tr[not (@class='featured')]/td[3]/p[@class='award-list-location']" .textContent



Featured:
-title/link - "//tbody/tr[@class='featured']/td[@width='200px']/a[3]" .href, .text
-majors - "//tbody/tr[@class='featured']/td[@style='width: 95px']" .textContent
-description - "//tbody/tr[@class='featured']/td[3]" .textContent
-nationality - "//tbody/tr[@class='featured']/td[3]/p[@class='award-list-nationality']"
-Host Countries - "//tbody/tr[@class='featured']/td[3]/p[@class='award-list-location']" .textContent

8/12 Notes:
-Keep working on IefaLeads
-I think I want it to work by looping over each result page, get all the information from all 12 pages, grab the results pages urls, and then loop through the urls to go to the pages and get the info
-I think it should be okay to do this, though loading the array with 1.2k leads might be a bit much, I'll have to run it and see how it goes
--Looks like today will be another babysitting day
-Doing initial testing, trying to get the textContent of the titlesDivs, it's giving me a cache error, not sure why. It doesn't seem to have a problem with the featured divs, but the normal ones are weird
--After commenting out the normal titles get (only getting featured titles), it tried doing links and gave the same error for normal links.
--Makes me wonder if my xpath is just wrong or something.
-Tried running it and just making it grab the divs and then print out how many it's grabbing, interestingly enough it's still only getting 25 even though there's supposed to be 100 on the page
--I think maybe the page is refreshing the cache *After* it initially only grabs those 25, which is why it can't get the attributes because technically those ones it originally grabbed no longer exist.
--So if I don't have it click the expanded view at all, it should just work.
---Confirmed, works.
--I would really like to be able to grab 100 at a time instead of having to click through 48 pages, but whatever... maybe I could try setting it to 100, then click the next page, then click previous page
-Found a work around! Click the expand to 100, then click next page, click previous page, then try running the thing to get the titles; now it gets all 100 instead of just 25, and solves the caching problem
--It's still kind of fussy because sometimes it'll look for the next button thing before the expand page is finished loading, it's kind of obnoxious
---Added in explicit waits to fix this problem, now works a lot more consistently
-Now not sure once again how I want to do this. If I decide I want to get every one of the results items before actually visiting the individual pages, it might be better to just have the get pieces functions
append their results to an overarching array and then start putting together those arrays after everything is gathered
-Or I could just make the arrays, append the arrays to an overarching list, and then when ready to go to the individual pages just pull the arrays apart and reconstruct them
--Might go with the option
-Okay, so it is able to get the stuff on the first page, but the second tries the second page it runs into a caching error. Might try the next/previous page thing again
--mmk so the next/previous thing doesn't help with this, might need to add explicit waits to the get stuff functions
---Explicit waits aren't helping here, because it's technically finding what the wait is looking for, it's just not the right one...
--Ugh, I'm not sure what the issue is. I tried doing a long ass wait but for some reason it's still pulling the wrong cache for each one
---Yeah I really don't know what the hell do to here, it's still accessing the old cache from the first page
---I put in an explicit wait until it's able to find the 99th normal thing, but that's not going to help it on the not full pages... uuuuuugh
---Might have a solution! Get the damn href of the next button and just use get
----Works!
-Thinking of deleting the thing that gets the description from the results pages and just get it off of the individual page because it's a lot more complete
--Will also do this for nationality and host country

-Begin work on getting the stuff from the individual scholarship page
-Not sure if these are formatted differently between the featured scholarships and the normal ones
--If there are different xpaths between them, just put in a check for each type (they're the same)

Sponsor - "//span[@class='award-sponsor']" .textContent (filter out the Sponsor: thing with re.sub)
Submission Deadline - "//h4[text() = 'Submission Deadline']/following-sibling::p" .textContent
Field of Study - "//p[@id='award-fieldofstudy']" .textContent
Award Amount - "//p[@id='award-amount']" .textContent
Description - "//div[@class='award-description padding_bottom_30']/h4[text() = 'Description']/following-sibling::p[1]" .textContent
Other Criteria - "//div[@class='award-description padding_bottom_30']/h4[text() = 'Other Criteria']/following-sibling::p[1]" .textContent
Source Website Link - "//th[text() = 'Link']/following-sibling::td/a" .href
Number of Awards - "//th[text() = 'Number of Awards']/following-sibling::td" .textContent
Host Institution - "//th[text() = 'Host Institution']/following-sibling::td" .textContent
Includes - "//th[text() = 'Includes']/following-sibling::td"
Nationality Required - "//th[text() = 'Nationality Required']/following-sibling::td" .textContent
Host Countries - "//th[text() = 'Host Countries']/following-sibling::td" .textContent

-IefaLeads is pretty much finished, wrote a unit test for it
-Need to create a table and write the insert function, then probably spend the rest of the day running the program

8/13 Notes:
-Feeling sick today, might not stay all day because dead
-The program seems to have run fine enough, it just died at the insert stage because I forgot to update my sql query...
--Once I update that it should run fine
--Oh my fucking god
---program ran through, all nice and happy, yay, but I forgot to run CleanText over the titles, and so a stray ' broke my program. Kill me.

8/14 Notes:
-Program ran through last night
-I'm not sure why the IefaLeadIds are all mixed up, but I guess so long as they have unique ones it's whatever, it's just weird that they're out of order
-Need to run classifier over IefaLeads, write the script to do that, also write class to get the info from IefaLeads
--finished
-Afterwards, write the Populate class for IefaLeads
-Going to run the classifier over the Iefa Titles and concatenated description + other criteria
-PopulateIefaLeadRequirements is finished, time to work on the next site

-Working on chegg now
--This one is going to be weird because the chegg thing works by loading new scholarships when you scroll to the bottom of the page
-Was able to write a loop to make the page scroll to the bottom and load the new scholarships until 500 scholarships are loaded
--I wanted this to be equal to how many matches are announced at the top of the page, because at any moment the amount of scholarships could change
--to where there's way more or less than 500 scholarships, in which case the loop will be endless
--Tried to capture the given number of matches, but for whatever reason that number always gets pulled in as 0; could be a caching error but not sure
--Thought it might be a caching issue, but it doesn't seem like anything I can really fix... And there's no way to do an explicit wait because I can't make those dynamically
-Tried a method to make it grab the initial number of scholarhips shown, then scroll, grab how many after shown after, then compare the previous amount to the new amount
--And then keep scrolling and refreshing those values until the first value equals the second, but can't do that because both grab before the scroll happens
--And there's no way to force the second one to wait. Oh well. Will just use the scroll until 500 method, which is terrible but whatever

-Stuff to grab from result page:
Title - "//a[@class='scholarship__title']" .textContent
Link - "//a[@class='scholarship__title']" .href
Deadline - "//a[@class='scholarship__deadline']"
Amount - "//a[@class='scholarship__amount']"

-Stuff to grab from individual pages:
Eligibility - "//span[@class='txt-3" .textContent
Application Overview - "//h3[text() = 'Application Overview']/following-sibling::div[@class='txt-3']" .textContent
Purpose/Description - "//h3[text() = 'Purpose']/following-sibling::div[@class='txt-3']"
Sponsor - "//h3[text() = 'Provider Organization']/following-sibling::div[@class='txt-3'][1]"
SourceWebsite - "//button[@class='btn-primary-sm go-apply']" try get_attribute('url')
--The url exists in the tag, but not in the properties display, so hopefully that works

OH GOD THEY HAVE DIFFERENT FORMATS ON DIFFERENT PAGES
Different page stuff:
Scholarship Question - "//div[text() = 'Scholarship Question']/following-sibling::div[@class='description']"
Description - "//div[text() = 'Description']/following-sibling::div[@class='description']"
Eligibility = "//div[text() = 'Eligibility']/following-sibling::div[@class='description']"
SourceWebsite = "//button[@class='btn-primary-sm save-profile chgsec_hostedsc-apply-ApplyNowButton chgser_sc']"
--I really have no idea where to get this one, the button doesn't have anything in its url...might just force the program to skip things with this sort of button

-ugh, literally what I was fearing would happen with the scroll thing happened. The amount of results changed, and so it broke the scroll loop
-And now it's being weird about getting my results page info. I'm so tired of this thing
--Maybe my deadines/amounts xpath is wrong...
---xpaths are right, but they're not finding anything. I have no idea what the hell is up with this site
---nvm they were wrong, I forgot to change a to div

-xpaths are fixed, running program, not sure if program is slow or hung
-for some reason it hung trying to get the links list. this site sucks.


8/17 Notes:
-Need to type up notes for Mike
-Continue working on CheggLeads, if I can't get things to work then will just say screw it and try a different one
--Potential solution for the program not grabbing the divs I need on the list page:
--See if you can get the same information on the individual results page and just pull it from there
-I figured out why it was seeming to hang on the first step: it wasn't actually hanging, I just called the wrong function and it created an infinite loop
-CheggLeads finally works, wrote the insert functions and added the table to the database, runs fine
-Need to run the classifier over the database and then make the PopulateRequirements thing
--Will need to write getdatabase info class
-Chegg is finished

-Work on FastWeb next
-So far this site is nice and easy to work with, definitely an improvement over chegg, will probably go by very quickly
-Results List Page Stuff:
-titles: "//h3/a" .textContent
-resultPageUrl: "//h3/a" .href
-sponsor: "//div[@class='provided_by']/p[not (@class='label')]" .textContent
-amount: "//div[@class='award']/p[not (@class='label')]" .textContent
-deadline: "//div[@class='deadline']/p[not (@class='label')]" .textContent

-Tried running it the first time, not sure why deadlines is having a bad interaction with CleanText
-It's kinda strange, verified that the xpath is right, and the program isn't having any problems pulling out the text content, so I'm not sure...
-Oh lol my loop for cleanText was looping over deadlinesDiv and not deadlinesList
--This is why it's kinda bad having things named similarly
--Now it runs fine

-Scholarship Page stuff:
-description: "//div[@class='description']" .textContent
-awardType: "//p[text() = 'Award Type: ']/following-sibling::p[@class='data']" .textContent
-numAwards: "//p[text() = 'Awards Available: ']/following-sibling::p[@class='data']" .textContent
-majors: "//p[text() = 'Fields of Study: ']/following-sibling::p[@class='data major']" .textContent
--Need to add re.sub method 'All Fields of Study' --> ''
-additionalInfo: "//p[text() = 'Additional Info: ']/following-sibling::p[@class='data major']" .textContent
-sourceWebsite: "//p[text() = 'Website: ']/following-sibling::p[@class='data']/a" .href

-FastWebLeads works perfectly fine, will make insert class and processing class before go home


8/18 Notes:
-Need to actually write up the thing for Mike today, don't forget!
-Check if FastWeb worked correctly, if not rerun it; add Tag column
-Write FastWebGetDatabaseInfo
-Write populate class, make requirements table
-Populate the thing
-Yay

-I'm thinking I want to try to make a superclass for the FundingClassifier run classes, so will do that first
-Need to add an update thing to PutThingsInTables - done!
-Wrote the RunFundingClassifier super class and implemented it in the relevant classes
--Didn't implement it for GrantForward or Pivot because those ones loop over a keywords list, and I'm not sure how a superclass will work with a keywords list
-Having all of the super classes is really convenient, because it allows for the subclasses to just be a couple of lines long. So nice.
-FastWebLeads officially finished

-Begin work on Scholarships360
-titles: "//h2/a" .textContent
-urls: "//h2/a" .href
-deadline: "//span[@class='due']" .textContent, filter out Due:
-amount: "//span[@class='amount']" .textContent, filter out Amount:


8/19 Notes:
-Okay, actually write up the thing for Mike. Now.
-Actually typed it up and sent the thing to Mike, yay.
-Continue working on Scholarships360, ugh

Stuff to get from the individual pages:
description: "//div[@class='entry-content']/p[1]" textContent
eligibility: "//div[@class='entry-content']/p/strong[text() = 'Who is eligible to apply?']/../following-sibling::ul[1]" textContent
amountInfo: "//div[@class='entry-content']/p/strong[text() = 'How much is each scholarship worth?']/../following-sibling::p[1]" textContent
deadlineInfo: "//div[@class='entry-content']/p/strong[text() = 'When is the deadline to apply?']/../following-sibling::ul[1]" textContent
sourceWebsite: "//span[@class='apply']/a" href

-Finished Scholarships360Leads, still untested
-Make table, make insert class, make process class

8/21 Notes:
-Scholarships360Leads appears to have run through and inserted stuff with no problems
-Actually, there seems to be an issue with my xpath for eligibility, amountInfo, and deadlineInfo as only the very first result even has them filled
--It seems to be because my xpath is looking for a node with really specific text, and the text changes from scholarship to scholarship (because they have the scholarship name inside them)
--Will try modifying it to use contains text and see if that helps, hopefully each eligibility and amountInfo and deadlineInfo have some sort of unique thing that they all share

Try these:
eligibility: "//div[@class='entry-content']/p/strong[contains(text(), 'eligible')]/../following-sibling::ul[1]"

amountInfo: "//div[@class='entry-content']/p/strong[contains(text(), 'How much')]/../following-sibling::p[1]"
"//div[@class='entry-content']/p/strong[contains(text(), 'How much')]/../following-sibling::*[1]"
deadlineIInfo: "//div[@class='entry-content']/p/strong[contains(text(), 'deadline')]/../following-sibling::ul[1]"


-ugh, this site is really inconsistent with what they want to label stuff. I really really don't like this
-going to need some elif statements to try to capture everything

eligibility:
"//div[@class='entry-content']/h3[contains(text(), 'Eligible')]/following-sibling::*[1]"
"//div[@class='entry-content']/h3[contains(text(), 'eligible')]/following-sibling::*[1]"
"//div[@class='entry-content']/p/strong[contains(text(), 'eligible')]/../following-sibling::*[1]"
amountInfo:

deadline:
"//div[@class='entry-content']/h3[contains(text(), 'deadline')]/following-sibling::*[1]"
"//div[@class='entry-content']/p/strong[contains(text(), 'deadline')]/../following-sibling::*[1]"
-nvm will continue working on this later, do something else now

----------------------NO MORE CRAWLING YAY------------------------(for now)
Want to start filtering out scholarships that are for specific schools that are not the UA
-So we need a way to check for this information and remove the bad stuff
-Train on IefaLeads
--Read through, if find scholarships that have specific uni/college requirements, make notes of what they say so you can use it
in the algorithm later
-Iefa leads might have been a bad choice for training, all of this seems to be study abroad stuff

Bad stuff:
-Check host institution, if there is one, and it's not UA, then it's bad
-Scholarships for studying in other states besides Arizona.
--Ex: 'attending school in Utah'
-lol basically mentioning any specific university so far
---but what about summer programs? summer program at other university, could be of interest to UA students
---study abroad
-other countries that aren't actually study abroad scholarships
--There's a difference between study abroad and actually attending school in a different country.
--Study abroad impplies temporary study where you will study at your home institution both before and after the completion of the study abroad
--While going to college in a different country, there is no home institution \
--I DON'T KNOW
-this is gonna be hard
--scholarships where the sponsor is a specific university (in the US) are probably scholarships *for* that university, so look at sponsor and name
--when naming a university outside of the US, check description info for study abroad ish terms
-mentioning a required nationality that isn't american
-Maybe: 'international student studying in the United States'
--This would be relevant to international students.
-Scholarships which say something like 'awarded upon admission to blah blah school'
--Look up the word School/University/College attached to any other capitalized word
-Requires nationality that isn't American. While there are a lot of international students at this school, that's a little restrictive
--And kind of no point having a scholarship that requires a particular nationality that may only ever fit a single student that uses SU ever
-mentioning specific cities that aren't Tucson... unless it's study abroad; mentioning specific countries
-reside in or attend school in non-Tucson/Arizona
-at a (other place) university
-academy

-Some of this stuff is just straight up weird
-The weird scholarship that wants to give money to middle school students...
-Some of these aren't actually even scholarships, but advertisements for people to apply to their school...

Thoughts:
-May need to use the ntlk pos tagger and named entity recognition to pull out organizations/locations
--This may be the most effective way to filter out scholarships that aren't related to Tucson

8/24 Notes:
-Today is weird cause school. I don't like it.
-Keep labeling
-made TokenizeIntoSentences class with static method

-Thoughts on filtering out specific non-UA universities/non-Tucson cities:
-Look up University/College/School (must be capitalized); get surrounding words (University of Blah or Blah University), if also capitalized then concatenate to uni and if not University of Arizona then mark as bad
-Check for both capitalized first letter and full capitalized words
-cities and states will be harder; might be able to default to not sentence initial capitalized words and compare them to Tucson/Arizona/United States
-if that doesn't work, then just use the nltk NER function, parse out all of the organizations/locations, chunk them together, compare to what I want
-Get list of country names, put in database; might also need country name adjectives (Australia --> Australian); if find anything besides American (and not also in same document as 'study abroad'), then bad
-might be able to look up uni/college/school and do the same thing as searching for the university names, gather surrounding tokens, if find capitalized words, then compare the capitalized words to America/American/etc etc and if not satisfied then bad
-if decide to run a check against all uppercase starting words, may need to check those words against a majors list
-specific high school graduates, this will be weird because yeah. Any UA scholarships looking for a specific high school will be a Tucson highschool, so...

----hands down, best option will be to run the NER parser cause most accurate and better than trying to do a regex search over text where people can do anything

-Finished labeling, will start by running the NER search over some of the labeled IefaLeads and see what comes up
-Need to figure out what should be part of the search (for the sake of consistency)
--While Iefa leads has the host institution pulled out for you, that's the only site that does that. I've been using the presence of a host institution as an easy way to decide if the scholarship is bad or not without having to look at the description
--Maybe make host instution an optional argument to feed into the program so that leads that do have that information pulled out can just feed it in there
--Host institution could also be Sponsor! Most of the stuff I've pulled out has sponsor information so this will work too
---Check sponsor to see if theres a University/College/School thing
--Otherwise, try appending the host institution to the concatenated description/eligibility stuff and see if the NER still pulls it out right

What to do:
-Pull out sponsor info
-Concatenated description/other criteria(probably will be eligibility for other things)
-First check sponsor stuff, if find University/College/School, then check to see if sponsor = University of Arizona
-Next check description info, sentence tokenize, word tokenize, pos tag, ne_chunk
-program requires maxent_ne_chunker and maxent_treebank_pos_tagger and words to work if need to use on another computer

-Tried out the ne_chunker, it's bleh at best, doesn't recognize University of Arizona as one entity, which could be really annoying
-It does however chunk together Arizona University... bleh
-University Of Arizona (capitalized Of) does get chunked together so this is good
-May need to do prep of the text, find 'of' that occurs directly after University/School/College and capitalize it if it's not already capitalized
--Can use either .capitalize or .title to do this
-not sure why sometimes Tucson, Arizona gets chunked together and other times it doesn't
-bleh
-okay, so if location words don't sometimes get NER'd right, then will have to do both NER parse and then, if still nothing found, then check over capitalized unigrams

-So far have been able to get it to check the extracted NERs against a list of locations and it's relatively fine, it'll return False for something mentioning the UA, which is good
-however, when tested against Albania it returns None. It should at the very least default to False, so it's weird...
-nvm, turns out I'm stupid, forgot to have the function return the boolean, not just print it

8/26 Notes:
-Only having work three days a week is weird
-I really don't have any idea where to go from here. Will test sponsor/organiztion filtering first and see how it goes
-added spideman project to personal github, cause yeah. code. interviews and stuff
-not sure why bitbucket keeps having icky problems. It's annoying.
-Just ran the classifier using just the sponsors, managed to get a 65% accuracy on the first run, not bad
-Tried running it using both the sponsors list and the infoText; took a lot longer to run (maybe about 2 min), accuracy of only 76%. I'm going to have Don-E move the rows I want to test on to a separate table
-New table made, time to make ALL the columns
-set up unit tests to run the program three times, first as a normal run then as a sponsorOnly and as an InfoTextOnly run so I can see the differences as I change stuff
-This is kinda weird, sponsor only and infoText only have the same accuracy, but different answers... not sure if it's just a coincidence or if I set up my accuracy calculator with the wrong arguments
--sponsor only: 65.28776978417267
--info text only: 65.28776978417267
WHY IS IT THE SAME WTF
-I've no idea. I checked the arguments I was feeding into the calculator, I dunno. Will try changing names just to see
-tried changing names, same accuracy. I dunno. whatever.
-Trying to force the loop to break the second it finds something badText-y in order to avoid overwrites
-This actually had an impact on the accuracy of infoTextOnly run: 65.10791366906474
--slight decrease but at least it's no longer exactly the same as the other one...
-need to fix the educational institution regex for instances of stuff like CollegeWeekLive. Should force it to only look for institutions with a space before and a non-word character after
-added 'US' to list of acceptable GPEs, but that brought down the accuracy... hmm 64.92805755395683
-adding spaces on either side of the education institutions in the regex really fucks it up 59.89208633093526
--  DON'T DO THAT
--I should really test these against the both test. I'm realizing that the accuracy is kind of doomed to be low simply because it kind of needs both to function.
-I'm just not sure what to do though. I want the separate things to be as accurate as possible. If there's no bad sponsors in the sponsor space then I want it to return that properly

Let's just work on sponsors for now:
-So far, all of the 'Yes' predicted responses seem to be right
-The 'No' responses are where the problem is
--Need to add more items to the regex
--Added in schools and academy, brought up accuracy slightly 66.18705035971223
--Also should put in a regex for strings of capitals in order to get stuff like NYU - brought up accuracy to 72.66187050359713
--Kind of tempted to add in program/programs - didn't really do much, dropped accuracy slightly so not going to do that
-Need to add 'universities' and 'schools' and 'colleges' - 73.20143884892086
-Something that sucks is that I won't be able to grab foreign language stuff
-I could have it first test over the unigrams then do a regex search on the whole thing...
-Added in a regex to look for Univ (to try to find other language words that are cognates for university) 73.56115107913669
-Fixed the acronym search to look for at least three letters 74.64028776978418
-Just realized my accuracy is going to be negatively skewed due to the 'Maybe' answers
-Might redo accuracy calculations to ignore those...
--Ignoring the Maybe rows, accuracy shoots up to 78.59848484848484
-Also beginning to see some errors in my own tagging, this is a good sign, will bring up accuracy
-Am realizing that the acronym thing might be a little overzealous. It works to grab all of the bad ones, but some of the good ones are getting eaten up
--Might add in some exceptions lists, and fix the regex to ignore things in parentheses
--The exception list helps, the parenthesis does not (parenthesis drops accuracy down to 72)
--by excepting LLC accuracy now 78.97727272727273
-Having 'Institute' as a bad word might be a little overzealous, but ehhhhhhhh
-Fixed the parentheses acronyms thing. First searches for acronyms, if finds, then searches for acronyms with parentheses around them; if find parentheses then ignores, else bad
--79.35606060606061 now

-At this point, the only thing that's being overzealously marked as bad are the odd Institute and the occasional acronym. Only 13 examples.
-Will try taking out institute and see what happens - NOPE
-Drops accuracy by over 4%, clearly institute needs to be a bad word

-There's still 96 examples where it's a bad scholarship but not being recognized as such
-Can also add lists of bad acronyms; added SWE to that group, current accuracy 80.11363636363636
-Very tempted to try running a NER search over the sponsors to pull out locations, but might be weird... not even sure if it would POS tag correctly
-Other than that, a lot of what's left is just stuff that must have been negatively tagged due to whatever's in the text
-Going to add a column to the table that already has the info text concatenated for ease of reading

8/28 Notes:
-Keep tuning thing. Joy.
-Going to shift focus from the sponsors to the info text, as there's not a whole lot left in sponsors that really jumps out at the moment.
--If necessary, try to filter out locations in sponsors if decide to test the NER parser on sponsors.
--Actually did just test the NER parser to see if it pulled out anything bad, it actually worked; will test more
---As in, it returned True for a bad item in 'Natural Sciences and Engineering Research Council of Canada', which means it probably pinged off of Canada
---Going to manually check to see if this is what really happened... Cause it's possible that it pinged off the whole thing as an organization, which might have made it mad
---Ran it manually so I could see the NEs extracted, it pulled out Canada which is good, and then that would flag the GPE filter to say no. So might be able to try implementing that into the sponsor filter
---mmk, nvm, it doesn't actually work. It liked the Canada one because there were non-capitalized words in the string, so the whole thing didn't get chunked together
---But 'Milwaukee Foundation' gets the whole thing chunked as an Organization, which is technically what it *should* do, but it's annoying. Means I can't use the NER to pull out GPEs reliably
----Unless there's a way to make it only look for GPEs? nvm there's no way to do that
----I LIED THAT'S NOT WHAT'S HAPPENING
----I actually just ran it, and for whatever reason it's pulling out Milwaukee as a person? I can't really set it to filter out people because, well, people
----Will try another one...
----Yeah don't run the damn NER parser over the sponsors, it's retarded.
New England Board of Higher Education =
(S
  (GPE New/NNP)
  (ORGANIZATION England/NNP Board/NNP)
  of/IN
  (PERSON Higher/NNP Education/NNP))
That's not supposed to happen.
-...I wonder what would happen if I turned off the caps. --> Absolutely nothing, doesn't pull out anything.
-TIL the NER parser relies 100% on capitalization. Woe betide me if any of these scholarships I'm trying to classify have weird capitalization
-I'm strongly tempted to see what would happen if I just run the whole damn thing through a ML algorithm. Will have to see.

-As of right now, with the sponsor checker about as tuned as I think I can get it for the moment, running a full test (sponsors + text) has a 77.87769784172663 accuracy
-Tells me that there's definitely some solid problems with the text search, as the sponsor search alone had an 80% accuracy
-I really do want to try running it through ML but I'm not 100% sure that my manual tags are right... will just wait for now...

-Now to work on infoText stuff
-As of right now, the parser works by tokenizing into unigrams, running the NER parser over the thing, and if it finds an organization with an educational institution
keyword in it, flags it as bad text
-This isn't really all that good for instances like CollegeWeekLive
-Will try rethinking how this parser works
-So, in the instance of CollegeWeekLive, it pulls it out as an organization, which is what it's supposed to do. The next step in the original parser is to check for the keywords.
--Maybe I could make it only check for those keywords followed by spaces?
-ugh just adding a space in the regex doesn't seem to help, will try something else
--not sure why though, College\s shouldn't match 'College'
----ahhh lol I see why it broke, I just did a join with \s| but College is at the end of the list so it didn't get the space
-now it works, doesn't flag CollegeWeekLive anymore, this is good
-So another problem - CollegeWeekLive also gets flagged as a GPE, which is really awkward. I have no idea why
-I really can't afford to have to babysit the NER search because it's doing stuff like this. Maybe have a filter for if it gets pulled out as an organization, remove from GPE list... It's fucking weird though
-This is so awkward
-Might need to make a GPE/organization list for the entirety of the info text, have each sentence add to it, then filter through them, since the NER parser might label something differently from sentence to sentence.
-So weird.
-That ended up working, so okay
-With the current fix, checked accuracy, dropped accuracy down to 62.23021582733813; this thing needs a lot of help
-Thankfully I've realized there's a way that I can see everything it's pulling out very efficiently by printing it, so will make another unit test just to do this
-Huge problem. This thing is obnoxious. It keeps pulling out lots of stuff as GPEs, and of course my GPE filter is having a fit.
--Stuff like 'Completed' is getting marked as a GPE.
-Will need a really good filter to flag extracted GPEs properly cause that's just not good.
-I just realized that the changes I made to it is literally flagging EVERYTHING as a bad scholarship. That is so not good
-I HAVE NO IDEA WHY IT'S BEING BAD
-I'm not very smart. It's showing everything as being tagged as 'yes' because I have the filter set to show me only 'Yes' tagged things. Nice job Kya.
-I wonder what happens to the accuracy if I don't use the otherCriteria stuff. Some of the stuff being pulled out as a wrong tag is stuff that is weirdly formatted in a bullet point and is making the NER parser mad.
-Actually kind of have to use the OtherCriteria stuff because a lot of it has university/country information that will be vital to classifying the thing
-I'm just not sure what to do here. I could do a search for bullet points and just uncapitalize the very first word that follows, but what happens if it's something that should be capitalized?
-Going to check out how my program tokenizes sentences and maybe if the ones with bullet points are coming back as shorter sentences, I'll filter out everything below a certain length. That might help with dealing with fragments
-Okay, so it turns out that the bullet points are not being transformed into separate sentences, but are all being put as the same sentence (since no punctuation)
-I'm going to try prepping the text before hand to clean up bullet-point esque stuff and sub in periods. See what happens
--Did absolutely nothing. Joy. I think it's because the periods end up in weird spots that it just doesn't help and the sentence tokenizer still says nope.
-Honestly I think it's because the NER parser is just really freaking weird. It tags 'Completed' in 'Completed application' as a GPE but 'Official transcripts' gets nothing
-It's really annoying

-Yeah I might not use the GPE search at all because it's pulling out a lot of bullshit
-Taking out the GPE NER search is really crippling though. I need to have some way to reliably pull out bad locations, but the GPE search is just awful
-I'll try the standford ner search and see how it goes
--Though unfortunately it doesn't have a nice chunking ability, so I'll have to write that in myself.

-Looking at the documentation for the Stanford NER tagger, I REALLY don't want to use it. There's damn near 0 documentation because it wasn't intended to work with python
-So have to use a wrapper for it, but then THOSE HAVE NO DOCUMENTATION EITHER
-So I'm sort of back at the beginning of either I can try to get a database of place names (really?) or just say fuck it
-I have no idea

-fuck it, going to set up a NB, see what happens


8/31 Notes:
-After resting for a few days, hopefully have more perspective on what options I can take to solve this problem
-Already feeling overwhelmed this semester, and it's only the beginning of the second week

Possible Solution:
-Have separate functions to parse Organizations/GPEs
-Feed into the function the tokenized sentences
-From there, Organization can continue as it already does (word tokenize, blah blah)
-GPEs will be different. Run regex to grab the first letter of each sentence and make it lower case
-Run regex to find bullets/asterisks, grab first letter and lowercase it.
-This should hopefully help to reduce the number of superfluous uppercase items in the text, and should therefore hopefully clean up the GPE parser

Other possible ideas:
-Try to get list of all countries/US states/major world cities, put in database
-Then run the results of the GPE parser against that list?
-Kind of defeats the purpose of using the GPE parser cause could just use a regex to do the same thing, but whatever

Update:
-So far, uncapitalizing the first word of the sentence and the first word after a bullet seems to have solved the problem. I"ve only tested on 10 things, but
none of them are pulling out non-GPEs in the GPE section anymore. Will keep checking on more stuff
-Noticed that for some reason 'College' isn't being flagged properly in organization
--Realized that I don't have a regex to check for end of string stuff...
-After checking over 50-ish things, there are some things that are getting pulled out as GPEs that shouldn't be, but significantly less than before
-Need a way to filter out the rest of these things
-Some of the stuff that's getting pulled out are capitalized majors/education related words
-I could run the GPEs through the majors list? Though that might hurt some of the area studies things
-I STILL NEED TO IMPLEMENT STUDY ABROAD
-Will implement search against majors list, that should remove some of the stuff, but I might straight up need an exceptions words list as I don't really have any other ways to prevent the GPE parser from grabbing them
-I could check everything against the unigrams and be like, if the same word appears at all but as a lower case word, it's probably not a named entity
--This might have a hell of run time, but it could be effective...
-Can start out by filtering out everything that is all caps that isn't two letters long (to allow for state abbreviations and stuff like US/EU)
-So had it filter through the majors list, realized it took out 'English' since that's in the list... Might need to go through the majors list and see what majors are just countries and yeah
-THIS THING RUNS SLOW NOW HOLY SHIT
-ugh. Adding in the filters is supposed to make it run better, but it's not... fml.
-Going to test the whole thing with the sponsors too and see what I've got - so far a total accuracy of 81.4%. That's not bad at all.
-Compared to the accuracy of the separate tests (sponsors only - 80.1; text only - 61.7%), the sponsors check is by far the most important, as it adds 20% to the
accuracy. It is able to stand alone. Adding the text search only increases the overall accuracy by 1.3%. That's still something, but not really...

-Going to insert the predicted stuff from the text only search and see what I can find to fix
-Forgot to check accuracy ratings against the stuff that isn't labeled as 'maybe'
--Text: 65%; Sponsor: 80.1%; Total: 85.8%
I AM REALLY SATISFIED BY THIS
-Going to try implementing the study abroad exception and see what happens
-Oh god I realized that my fixing of the 'English' exception was adding it to the overall list and not to the relevant list, need to see what happens... I'm anticipating an increase in accuracy
-Increased accuracy to 65.5%
-Will try adding the study abroad thing in now
-Only increased accuracy a little bit (65.5 --> 65.53) but that's still better than nothing at all
Overall accuracy up to 86.74%. I think it's good now.
-Also added in 'teach abroad', brought up accuracy to 87.1%

Things I've noticed that I really can't fix:
-If the InfoText only ever refers to a educational institution by its acronym, and the sponsor text doesn't have it too... can't really do much there
-Sometimes a location isn't pulled out as a GPE, but instead as an organization.
-Sometimes something gets flagged as a GPE but it's not. I can't think of much else to do with this that I haven't already tried...
-Instances of education words used but aren't actually a college/uni

-So, if the classifier is done, can probably start running the classifier over the existing scholarships
-Tables to work on:
-CheggLeads
-CollegeGreenLightLeads
-FastWebLeads
-FatomeiLeads
-GrantForwardLeads
-IefaLeads
-PivotLeads
-Scholarships360Leads
-ScholarsiteLeads
-UnigoLeads

-Starting out by making a superclass to use with each of the specific class - RunBadScholarshipClassifier
-Finished RunBadScholarshipClassifierOnCheggLeads
-I'm really iffy about how well this thing works, but I can't think of any other way to improve it so just kinda go with it

9/2 Notes:
-Because I'm really not satisfied with how much I was able to filter out the bad-tagged GPEs, going to try making a database of locations to check them against
-Going to make a table of countries/capitals; a second table of states/capitals; third table of major US cities and major world cities
-Then will have classifier call each of these lists, filter out anything that isn't there
-Might also filter the Organizations through these lists in case a GPE is incorrectly tagged as an org
-Would prefer to still use the NER parser rather than just use a regex of the lists because might run a bit faster.
-Might also need to add the adjective form of the country to the countries list. So, for example, Japan would have Japan, Tokyo, Japanese

-Made the countries/capitals table and the US states/capitals/major cities table
-Forreal, if this list can't capture at least some indication of any GPE the program could toss at it, then it's so obscure that it won't even matter
-Updated the classifier with the list, and ugh. Dropped text accuracy down to 61%. Not sure what the issue is
-going to reimplement the thing to print out the gpes and see what the problem is
-That's really disappointing though.
-Okay, realized there were a lot of general GPEs that got filtered out (stuff like European, Asian, etc), so I just added those back to the list, accuracy back up to 64.2%
-Will look back through and see if there's anymore that need to be added back in
-Still need to implement the GPE search over the organizations search for the stray GPEs that end up in there
-Going to add in a filter for English to try to capture 'English language' as an exception- AHAHAHA DON'T FUCKING DO THIS THAT WAS BAD (51%)
-I am really satisfied though that this has pretty much completely solved the problem of bs GPEs getting through. Now it's just a matter of readding GPEs that should be tested
-Trying to add a filter for studyabroad/teach abroad that forces the gpe to be a foreign country/city (to prevent something like 'need to live in utah for study abroad') - 65.3409090909091
-Yay! Filtering out mistagged GPEs from organizations back to GPEs is an increase in accuracy - 67.23484848484848, this is all so good
-Added all of the extra GPEs that were missed in testing, accuracy up to 67.42424242424242
-So overall, the whole thing raised accuracy by 2ish percent, which isn't a whole lot, but it'll significantly reduce the number of false positives that the program would have from mislabeled GPEs
-So I anticipate that the overall accuracy should have been increased by quite a bit more...
--An increase from 87.1% to 88.82575757575758; not as much as I was hoping, but it's still good
-For some reason 'district of columbia' isn't working too well, but I'll worry about that later

9/4 Notes:
-I really don't want to play with the Classifier anymore.
--Added America and North America to otherGPEs, added North America to allowed GPEs, not sure if that was a good idea because while it's non-specific, it's also kinda broad
-Need to write the rest of the classes to run the Classifier over the rest of the databases, then run them
-Ken sent email to check out new site for crawler, so need to do that
-Meeting at 11ish

-Apparently 'Independence' is a city somewhere, but I don't need it to be a GPE, so I need to remove that from the list
--Fixed, just added a conditional statement for it
--I could probably just remove it from the database, which probably would make more sense... will do that instead
-I really really need to fix Disctrict of Columbia. It's bothering me. I don't know what to do with it but I don't like it
--Fixed it. Do regex search over info text for district of columbia, if found, add to filteredGPEs, remove columbia from filtered gpes
--Added district of columbia to okay gpes because it's annoying otherwise
-Working on FatomeiLeads classifier thing, this one is weird because for Fatomei there was no way to actually grab the sponsor information, so this one will have
to just run over the descriptions. It'll be crap at best.

-Very tempted to add in a regex search for the non-filtered regexes to get dumb stuff that escapes like City + State or State Colleges, etc.
-After looking over everything, definitely going to attempt to implement a regex search over the other GPEs/Organizations. I'm seeing a couple of game-changing GPEs popping up
--The regexes will be huge though, so it'll have quite a bit of runtime...
--Also not sure how to handle the couple of instances of ' in words, might need to do a regex replace over them to add a \
---nvm apostrophes don't need to be escaped
--Will end up needing an exception for race stuff. Don't want African American to return 'African' and 'American'


Finished classifiers: FastWebLeads, Fatomei, GrantForward, CollegeGreenLight, Chegg

9/9 Notes:
-Not sure how much of the regex search I got implemented last week... having a break is good but I didn't take good notes on what I got done so who knows
-I think so far I've got the regex search running over the GPEs, so hasn't been implemented for organizations yet. Not sure if ran tests on it yet so will do that
-Seems like it brought up text-only accuracy just slightly, will test on full thing; brought up accuracy to 89%, so improvement
-Will implement to search on organizations, then should be finished with the whole thing
-Did the implementation, it doesn't seem to affect the test thing at all, probably because there weren't a whole lot of scenarios in the testing data where a regex search run over the organization would make or break it
-It's pretty much done though.

-Potential issues: typical racial terms like American Indian, Alaskan, Asian, etc. will pose problems, but ehhh
-Yeah will need to filter these out, beginning to have problems
-Was sort of able to implement a filter to not pull out 'Alaska' if encounter 'Alaskan' or 'Indian'/'India' if encounter 'American Indian', so that's okay
-Other than the handful of issues it's having with overzealously filtering out Alaska/India(n), the gpe regex is a huge success. I don't see it so much in the testing data
but in the normal data there are a ton of instances where the gpe regex search is having a huge effect. So yay!

-need to get figures for Ken on how many scholarships pulled out
Chegg: (59) 48
CollegeGreenLight: (26) 26
FastWeb: (95) 81
Fatomei: (830) 334
GrantForward: (36517) 1171
Iefa: (1161) 556
Pivot: (19102) 2325
Scholarsite: (95) 95
Unigo: (91) 91

Total: 57976 total, 4727 scholarships (8%)

-Need to finish writing the implementation classes, then ask Don-E what to do next
-Still need to do: Iefa, Pivot, Scholarsite, Unigo

-Things done today that haven't already been noted:
-added functionality to remove gpes based on existing phrases in infotext, such as African American, Asian American, District of Columbia, etc.
-PivotLeads bad scholarship classifier
-Updated PivotLeadsGetDatabaseInfo to work with optional keywork parameter; added sponsor function
-Removed redundant entries to otherGPEs since the regex search made some of them useless


9/11 Notes:
-Meeting today at 11, talk about project, figure out what to work on next.
-Will rerun the classifier over Pivot, see if there's anymore tweaking to be done
-Otherwise, write classifier class for Scholarsite and Unigo, then ask Don-E what to do next
--ScholarsiteLeads doesn't have a getDatabaseInfo class, need to write that
--I just realized scholarsiteLeads doesn't need to have the thing run over it, as that site is set up by university, and all I have pulled out is UA specific stuff. So nvm.
-Realized that somehow the Scholarshipsp360Leads database got messed up, so reran the thing to populate that database, need to run the funding classifier over it
--Write the getDatabaseInfo class, run funding classifier, then run bad scholarship classifier
-I just realized that USA wasn't in the good GPEs list, that is so bad...

New Longish Term Goals:
-Need to Learn C#
--This is going to suck
--Going to rewrite pretty much everything that's been done so far into C#, so will get lots of practice
--Will be good for resume and future jobs stuff

-Get Fellowships #s for Ken
--Send email

-Crawl website in email

-Fix parsers
--majors, gpa, class status

Fellowships numbers
Chegg: (59) 2
CollegeGreenLight: (26) 0
FastWeb: (95) 1
Fatomei: (830) 262
GrantForward: (36517) 2743
Iefa: (1161) 235
Pivot: (19102) 3481
Scholarsite: (95) 0
Scholarships360: (49) 2 fellowships 39 scholarships
Unigo: (91) 0

Total: 4766 scholarships (8.2%), 6726 fellowships (11.6%), 58025 total


9/14 Notes:
-yay watching C# tutorial videos, will keep notes here on stuff I learn
-Console = the same thing console always is, it's basically where stuff gets printed out for the user
-Console.WriteLine() = print
-Use "" for strings, not sure if '' works yet
-Console.ReadLine() makes the console window pop up so you can see it and read what you told the console to write
-Single line comments = //; multiline comments = /* ... */
-Lines have to end in ; (end of line marker)
-To format code conveniently in VS, go to Edit, Advanced, Format Document
-static void Main is basically def Main, type the main code executeables here

9/16 Notes:
-When using Console.Read() it'll only show the things before that line. So you can't have multiple of those cause it's only gonna show the stuff before the first one
-variable names are case sensitive as usual
-use var when you either don't know what to call a particular data type, or if you don't want to explicitly say what something is
-otherwise just use string/int whatever
-if you want to convert an int to a string, use blah.ToString()
-int.Parse(stringNumber) converts a string that has a valid int to an int. Int then behaves like int (can be addeed and stuff)
-dude this is cool
-if you want to capture user input, do something like userInput = Console.ReadLine() and it'll read in what the user typed in and store it as the variable
-Console.ReadLine() does a lot of stuff, sort of confusing but okay
-So if I typed in 'kitty' it'll save the value as 'kitty'
-Conditional statements:
-the if statement is in parentheses like
if (userValue == "kitty")
{
    Console.WriteLine("You won a new kitty!")
}
-Turns out you don't actually need {} when the if/else if/else statements are followed by a single line of code. Otherwise you need to have the {}
-Visual studio's GIT thing is poop. Good luck if you need to revert anything. Need to ask Don-E to take a look at why sourceTree isn't working cause this sucks
-String interpolation is really stupid. For newer versions of C# you could do something like
string cat = "cat"
string iLikeCats = $"I like {cat}s"
-but VS 2013 doesn't like that so you have to do:
string iLikeCats = string.Format("I like {0}s", cat)
-And if you wanted to print that you could do something like:
Console.WriteLine("I like {0}s", cat)
-This is strange but okay

-Time to start rewriting stuff. This is going to be interesting
-Will start with the basic Parsing stuff:
-Parser, GPA, Majors, ClassStanding

9/21 Notes:
MOre C# stuff, rewrite regexes to use regwhy system, weird, okay.
Example of regex conversion below
original regex from GPAParser: 'g\.?p\.?a\.?|grade\spoint\saverage|maintain'
regwhy equivalent

var GPALanguageRegWhy = new RegWhyExpression();
                List<string> literals = new List<String>();
                literals.Add("grade point average");
                literals.Add("maintain");
                GPALanguageRegWhy.Append("g");
                GPALanguageRegWhy.MatchZeroOrOneToSearch(GPALanguageRegWhy.Characters.Period);
                GPALanguageRegWhy.Append("p");
                GPALanguageRegWhy.MatchZeroOrOneToSearch(GPALanguageRegWhy.Characters.Period);
                GPALanguageRegWhy.Append("a");
                GPALanguageRegWhy.MatchZeroOrOneToSearch(GPALanguageRegWhy.Characters.Period);
                GPALanguageRegWhy.MatchAnyofTheseStringsToSearch(literals);
                GPALanguageRegWhy.Append(GPALanguageRegWhy.Characters.OrCondition);
                literals.Clear();
                literals.Add("maintain");
                GPALanguageRegWhy.MatchAnyofTheseStringsToSearch(literals);
                return GPALanguageRegWhy.SearchPattern;

                /*
                GPALanguageRegWhy.Append(GPALanguageRegWhy.Characters.OrCondition);
                GPALanguageRegWhy.Append("grade");
                GPALanguageRegWhy.Append(GPALanguageRegWhy.Characters.AnyWhitespace);
                GPALanguageRegWhy.Append("point");
                GPALanguageRegWhy.Append(GPALanguageRegWhy.Characters.AnyWhitespace);
                GPALanguageRegWhy.Append("average");
                GPALanguageRegWhy.Append(GPALanguageRegWhy.Characters.OrCondition);
                GPALanguageRegWhy.Append("maintain");
                 */ this goes in place of the literals if you didn't want to use the .MatchAnyOfTheseStringsToSearch function

-we managed to get GPAParser up and running, so that's good.
-the regwhy system is kind of weird when making the regexes (it's not exactly the same as the default regex) but they work well enough
-Need to work on frame work for ClassStandingParser. Need to become familiar with using SQL with C#

9/23 Notes:
-Finished rewriting ClassStandingParser to C#, C# works weird in the conversion but it's working so its okay
-Rahul wrote the GenderParser so that's also done
-Will attempt to convert Majors parser a bit
-conversion of majorsParser going pretty well, pretty much finished except needs RegWhy conversion

9/28 Notes:
-YAY CRAWLING I'VE MISSED YOU OMG
-crawl website: http://www.mastersineducation.net/scholarships/
-see if it actually has anything on it worth crawling (cross fingers)

-it has stuff so yay
-Editor's picks stuff first, then scholarships
-grab clicky divs, click all first, then pull

-clicky divs: "//section[@class='scholarships']/div[@class='tab h-results']/div[@class='h-result js-has-toggle']/div[@class='h-result-header js-toggle']"
-title divs: "//section[@class='scholarships']/div[@class='tab h-results']/div[@class='h-result js-has-toggle active']/div[@class='h-result-header js-toggle active']/h3"
only works after clicky divs are clicked, use TextContent to get the title

9/30 Notes:
-continue working on MastersInEducationLeads

-title divs: "//section[@class='scholarships']/div[@class='tab h-results']/div[@class='h-result js-has-toggle active']/div[@class='h-result-header js-toggle active']/h3"
only works after clicky divs are clicked, use TextContent to get the title
-amount divs: "//dt[text() = 'Amount']/following-sibling::dd[1]" textContent
-deadline divs: "//dt[text() = 'Amount']/following-sibling::dt[text() = 'Deadline']/following-sibling::dd[1]" textContent
-description divs: "//dt[text() = 'Amount']/following-sibling::dt[text() = 'Deadline']/following-sibling::dd[1]" textContent
-link divs: "//div[@class = 'h-result-header js-toggle active']/following-sibling::div[@class = 'js-target hide scholarship-content']/p/following-sibling::div[@class='text-center']/a[@class = 'btn']"
href

turns out the scholarships section has different xpaths for its elements, so...

clicky divs: "//section[@class = 'scholarships']/div[@class = 'tab']/section/div/div[@class = 'h-result-header js-toggle']"
titles: "//section[@class='scholarships']/div[@class='tab']/section/div/div/h3"

the deadlines div is acting really really weird...
deadlines: "//dt[text() = 'Renewable']/preceding-sibling::dt[text() = 'Deadline']/following-sibling::dd[1]" textContent
description: "//section[@class = 'scholarships']/div[@class = 'tab']/section/div/div/p"
link: "//section[@class = 'scholarships']/div[@class = 'tab']/section/div/div/p/following-sibling::div[@class='text-center']/a[@class = 'btn']"

nextpage button: "//a[@title = 'Next']"

mastersInEducationLeads is pretty much done


10/2 Notes:
-after a bunch of stupidity trying to get MastersInEducationLeads to actually work, it has finally worked and the stuff has
been inserted into the database.
-going to classify the scholarships and then try to run badscholarship classifier on it
-made MastersInEducationLeadsGetDatabaseInfo class, so far has titles, descriptions, and ids things

Going to attempt something that may or may not be good
-There's a lot of criteria that goes into identifying which class year a scholarship is referring to. Enough nuance that
a simple regular expression search isn't really going to cut it
-Since there's a lot of data already labeled by the researchers for class year and scholarship information, I could perhaps use that info
to build a vector based classifier
-One potential issue already: a lot (if not all) of these have multiple labels attached to them, so how to handle multiple classifications
-Could have something trained on each possible classification, but ehhhhh. That could be very time consuming to run, but it could be effective
-Will start by focusing on a single label or group of labels. Will have to see if any are mutually exclusive.
-Luckily if I do the single groups there's a lot of positive and negative examples to use.
--This may not be the case for all of the possible classifications

Things to consider:
-feature selection
-The training data and the testing data are completely different. What's in the database is very carefully written versus the raw website data. This could potentially be very bad.
--Granted, with proper feature selection this might be a non issue, but I don't know... If the feature selection has to be very specific then it defeats the purpose of the classifier

10/5 Notes:
-Need to write class to get database information with RequirementNeeded where clause. Need to use sql LIKE statement
-This is pretty much done
-Nevermind, I need to set this up to make the RequirementNeeded clause optional, as well as give an optional parameter for NOT
-I'm already apprehensive about doing this this way because I honestly don't understand a lot of the logic behind some of these labels
-For example, just looking at the 'Junior' label alone, more than half of the ones I'm seeing don't mention really anything to do with junior at all
-Also issues with a scholarship being labeled 'freshman, sophomore, junior, senior' when the scholarship mentions 'undergrad'... I don't know how to make it label that particular way
This is going to be really awful

10/7 Notes:
-Work on feature selection
-Start with unigrams + bigrams; remove capitalization, keep stopwords for now
-Made the class MakeDataSetClassifyClassStatus, takes a class term to use, like 'Junior'
-has a function MakeTrainingAndTestingSet which takes a percentage value between 0 and 1, added a unit test to enforce this
-need to download winpython 3.4 because even though I'm not importing scipy, sklearn's linear regression needs it.... and I really
don't feel like figuring out how to compile scipy on this computer right now
-wrote the class to train and test the logistic regression classifier

-need to make sure that functions are actually returning the right things lol
-this will take a while to run so hopefully it will run overnight and be fine

10/12 Notes:
-So the classifier was successful, and on the first run for 'junior' it had an 81% accuracy - not too shabby
Results for label 'Junior':
Accuracy:	0.8136054421768707
Precision:	0.8138138138138138
Recall:		0.7832369942196532
F1:		0.7982326951399116
Results for label 'Other':
Accuracy:	0.8136054421768707
Precision:	0.8134328358208955
Recall:		0.8406169665809768
F1:		0.8268015170670038

-First major tweaking - fixed it so it only grabs sentence specific bigrams instead of grabbing bigrams across sentence boundaries
    -need to test to see if this has any real effects on accuracy
    -okay so it did, small increase to 82% yay
Results for label 'Junior':
Accuracy:	0.8217687074829932
Precision:	0.8096514745308311
Recall:		0.8342541436464088
F1:			0.8217687074829932
Results for label 'Other':
Accuracy:	0.8217687074829932
Precision:	0.8342541436464088
Recall:		0.8096514745308311
F1:			0.8217687074829932

-try taking out stopwords, see if that has any effect
    -another small accuracy increase, yay for small victories
Results for label 'Junior':
Accuracy:	0.8231292517006803
Precision:	0.8149171270718232
Recall:		0.8240223463687151
F1:			0.8194444444444444
Results for label 'Other':
Accuracy:	0.8231292517006803
Precision:	0.8310991957104558
Recall:		0.8222811671087533
F1:			0.8266666666666667

-Going to try testing this on some other labels to see if this decent accuracy rating is across all of them or just specific
to junior
    -this is actually pretty interesting, 'Senior' has much higher accuracy than junior at 85%
Results for label 'Senior':
Accuracy:	0.8517006802721089
Precision:	0.8723809523809524
Recall:		0.916
F1:			0.8936585365853658
Results for label 'Other':
Accuracy:	0.8517006802721089
Precision:	0.8
Recall:		0.7148936170212766
F1:			0.755056179775281
    -hopefully all of the others follow this trend instead of having some awful drop off somewhere...
    -will try again for Masters Level Graduate
Results for label 'Masters Level Graduate':
Accuracy:	0.8462585034013606
Precision:	0.7540983606557377
Recall:		0.6699029126213593
F1:			0.7095115681233933
Results for label 'Other':
Accuracy:	0.8462585034013606
Precision:	0.8768115942028986
Recall:		0.9149338374291115
F1:			0.8954671600370028

    -and once again for High School Senior just to have another value to add into averages
Results for label 'High School Senior':
Accuracy:	0.8598639455782313
Precision:	0.7848101265822784
Recall:		0.7815126050420168
F1:			0.7831578947368419
Results for label 'Other':
Accuracy:	0.8598639455782313
Precision:	0.8955823293172691
Recall:		0.89738430583501
F1:			0.8964824120603017

-So the average across (at least) these tests is 82.3 + 85.1 + 84.6 + 85.98  / 4 = 84.5%
-I am okay with this
-Will avoid tweaking any further unless absolutely necessary, can't think of anything obvious to try that might bring up
accuracy; could try trigrams later
-Going to declare some text files and save the models trained over all of the current data

-Need to figure out how to store training data and then read it back into the classifier so that it doesn't have to retrain every time, but not sure how to do this
-Use pickle to save to datafile
    -Code will look something like
    import pickle
    blah = LogisticRegression()
    blah.fit(blah blah)
    saveFile = open('savefile.txt', 'wb')
    pickle.dump(blah, saveFile)
    saveFile.close()

    later...
    import pickle
    saveFile = open('savefile.txt', 'rb')
    blah = pickle.load(saveFile)
-So, ultimately, want to tweak each model to run at maximum accuracy, then want to do some sort of ensemble classification
-Run each model for each label over the data, if for a given example two models return a label (non-other label) then assign that label
-Need a way to pull out the predicted labels from the frame in order to save them
-Also need to pull out id numbers from the database and push them along to the training/testing frames so when saving
predicted labels to the database we know which label goes where

-I just realized that there's going to be conflicts between 'senior' and 'high school senior' because the LIKE sql statement doesn't care...
-was able to resolve this

-Also just realized that if I want to run the classifier from a pretrained file, I will need to make a slightly different class because all of the conditional
statements would be obnoxious
-Will write this and then make a superclass for the shared functions between this one and the one that is training and testing from the same dataset

-So my life sucks
-Ended up writing a completely separate class for pretrained, since it shares almost no functions with the untrained version, so no superclass really needed
-Did however realize that pretrained does rely on the featuresValueCountsIndexes collected during training in order to make the testing vectors,
so in order to import those to the pretrained file, need to save those to a file too.
-There's now a billion files. I'm not even sure if I've gotten everything all together because there's just so much crap
-Every time something dies randomly due to a typo, I too die a little inside

-Okay, so was able to run it, it runs, yay yay yay
-Going to set compy to train this stuff while I'm gone, and then should be able to do more later

10/14 Notes:
-Still having problems with my unit tests not able to find and connect to the right files... kind of annoying.
-So need to rerun each training by hand to make sure everything works...
-a huge part of the issue is that I'm having to use file paths relative to the unit test, which is annoying as hell whenever I move things around
-should be okay now though

10/16 Notes:
-Going to attempt to build an ensemble classification system using trained models
-Need to make new table column to store results of this method
-Potential steps
1. read in table rows, get concatenated data, feed in data list + ids list to classification (arguments to main system)
2. class itself pulls models + fvcs from directory, ready to classify
3. for each model, call ClassifyClassStatusFromPretrainedModel. Needs to return the data frame with predicted values
    -this is assuming that each row in the dataframes all line up together. This shouldn't be a problem
    -in that case, might be better to just have it return the list of predictions, as the main class will already have the
    list of ids already, and the predictions should all be in order...
4. iterate through each list, pull out id and related predictions; declare a list, check each prediction, if not 'other' then
add to the list, return the list
5. store predictions list into database. figure out how to compare predictions list to db list. Should be okay

-This is pretty much taking a very long time for each run, had some issues with indexing but should be okay. Will inspect output on Monday
when come back in

10/19 Notes:
-Looks like everything ran relatively well with the ensemble classifier. Was able to get the program to return a list of
each non-Other match for each scholarship. I'm not sure overall how accurate the classifier is (that, and it's a little
ridiculous to test against your training data). Will run it again, this time storing the predicted labels in the database
and do some comparisons
-this really does take forever to run
-finished classifying and stored predicted labels in the database
-wrote class to compare the ensemble predicted labels to the actual labels
    -Interestingly enough, despite the fact that the individual classifiers have really good accuracy, the ensemble is kinda crappy
    -Only have exact match accuracy of around 17%, which is pretty dismal
    -Really comes down to the 15% average bad labels being scattered everywhere
    -Will make other functions to compare label lists of varying sizes to get stats for those.
    -Added calculations for accuracy within lists: averaging about 56.46% accuracy within predicted labels
        -So on average, 56% of the predicted labels in a given label list are actually right...
        -Not very good honestly

-I'm not entirely sure how to make the ensemble classifier work better. The separate parts work fine, but ugh.
-Perhaps more training data for the individual ones, but that still doesn't help that much

-Reading online about multilabel classification (multiple labels on single target, different from multiclass where you separate
targets into multiple different classes, and receives only a single label). Might try this.
-It seems like what I was already trying to do was a One-Vs-The-Rest classification system, where each class has own classifier
    -I could try using sklearn's version of this and see what it comes back as.

-So how to use the OneVsRestClassifier
-Seems like it needs to use SVC from sklearn.svm; I don't know the difference between the types, though. Not sure which one
to use with my data
-I need to figure out how to format Y values
-should be a list of lists, assuming that those are lists of labels? Will have to see lol


from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import SVC

make features vectors
X = features vectors
Y = labels

classify = OneVsRestClassifier(SVC())
classify.fit(X, Y)

10/21 Notes:
-Try implementing the OVR classifier, see what happens
-Need to get more info about how the labels should be fed in, should they be a list?
-Looking at the examples used on the website, the Y values are a 'tuple of lists', so I"m guessing a list?
-I'm going to try importing the thing they used and print out the Y values so I can see them
-Okay, after testing, it is indeed a list of lists.
-Realizing that the OVR needs another classifier to use with it as the base binary classifier.
    -In the examples it uses SVC (support vector classification)
    -so theoretically I could use the LR classifier in its place
    -Will try both and see what happens
-Rewrote makeDataSet class to use static methods and not be retarded. Something's wrong with it though...
    -turns out I just didn't include an argument, all is well

-Need to make webcrawler for Goodcall http://www.goodcall.com/scholarships/search
-Ken wants another crawler done for Unigo. https://www.unigo.com/scholarships
    -I'm pretty sure the one I have done will be enough, but will recheck it out for thoroughness' sake

GoodCallLeads Info
title divs: "//div[@class='main-details clearfix']/h2/a" .textContent
more info divs: "//div[@class='one-card-actions']/a[@class='action-button info']"
numawards: "//div[@class='award-count']", filter out '# Awards'
amount: "//div[@class='amount']" filter out 'Amount'

result page stuff
description: "//div[@id='main-column']/p[1]"
sponsor: "//div[@id='main-column']/p[2]"
school year: "//tr/td[contains(text(), 'School Year')]/following-sibling::td"
major: "//tr/td[contains(text(), 'School Year')]/following-sibling::td"
gender: "//tr/td[contains(text(), 'Gender')]/following-sibling::td"
ethnicity: "//tr/td[contains(text(), 'Ethnicity')]/following-sibling::td"
grades: "//tr/td[contains(text(), 'Grades')]/following-sibling::td"
test scores: "//tr/td[contains(text(), 'Test Scores')]/following-sibling::td"
geography: "//tr/td[contains(text(), 'Geography')]/following-sibling::td"
deadline: "//span[@class='deadline data']", filter out stuff in parentheses
essay info: "//div[@class='listing-info']/h3[contains(text(), 'Essay')]/following-sibling::p"
-need to be able to grab multiple instances of this, return a list of these things
essay length: "//div[@id='essay-length']"
-same as essay info
-might want to combine each essay p with its associated length div
external link: "//a[@class='action-button visit-site']" .href


10/23 Notes:
-Need to email Sandiway and Peter to see if they will be on my internship committee.
    -Emails sent, now time to wait. Hopefully they don't say no because I don't have anyone else I can really bother.
-Continue working on GoodCall leads
-It's pretty much finished, just needs to be run; will fix runtime errors as they occur
-I really really hate webscraping. Hit shift once and the entire thing just dies.

10/28 notes
- need to rerun goodcall leads stuff, didn't filter out everything properly
- added lines to the insert class to update the existing db entries
-both sandiway and peter have agreed to be on my committee, which is awesome
-will try to have internship report first draft done by the end of the semester

10/30 Notes:
-GoodCallLeads ended up running through okay, managed to update everything
-Only issue is that I forgot to filter out stuff in parentheses for deadline stuff, so I will have to add that in.
    -not going to rerun it today, as it would take all of my work time and babysitting this thing for 7+ hours with
    no netflix is extremely dull.

-Going to start back on trying to implement the OVR classifier.
-Also need to check out Unigo again (see if I need to update that classifier), and https://app.oregonstudentaid.gov/Catalog/Default.aspx

-built the entire OVR classifier, wasn't too bad, still untested
-godspeed, OVR classifier, godspeed
-for christs sake make sure the right damn interpreter is on
-THINGS ARE BREAKING AND I DON'T EVEN KNOW HOW THEY COULD BREAK WTF
-I think the issue was that when trying to make the training and testing sets for the multilabel system, I didn't call
    the makeDataSet function correctly - the arguments for the dataTextList and the labelsList were mixed up.
    should be fixed now
-Now having issues with immutable types. For some reason it's throwing a type error over the format of my labels, so I'll need to figure out how to fix this.


11/2 Notes:
-I really need to figure out how to format my list of labels for each training instance, otherwise fucked.
-In the original example given, the make_multilabel thing, the Ys are given as a list of lists. Need to check more into that.
-Confirmed that it's a list of lists. Why is the thing being bad then?
-Did a test fitting, worked okay.... so... bleh
-Okay, so made a list of fakeYs, was a list of lists, thing didn't give me any problems, so that means that my original formatting is all fucky somewhere
-I DON'T KNOW WHY IT'S STILL BEING BAD
-CLEARLY THE DATABASE IS FINE, SO THERE'S SOMETHING WRONG SOMEWHERE ELSE.
-WTF
-So something went really horribly wrong somewhere lol. For whatever reason, every training label is in fact the entire list of list of all the labels.
-This thing needs Jesus.
-I need to figure out what the hell is passing all of the damn labels list as each individual label. Probably somewhere in the MakeDataSet class
    -Can confirm, something is bad here
    -Turned out that my makeDataSet function is kinda shitty, was intended to work with both lists of label and a single label string but was
    just passing the entire label argument as the label, made sure to add in a check for whether that argument is a list or a string and
    pass stuff appropriately
-IT SHOULD FINALLY WORK NOW
-PLS WORK
-Okay, so now that the labels thing is fixed, it looks like it doesn't seem to have any problems with training...
    -Now just need to see what is up with the testing. It's giving me a pandas error for the predictions, so I'm not sure if they're just not
    matching up right (if it's off by one) or if something else is wrong
    -turns out it was making the testing vectors of the training set instead of the testing set, simple fix
-The entire thing works, first run through (with 80% of the data as training) gave an accuracy of only 22%
-That's not horrible, because it's still an increase over the other ensemble classifier, but at least for the other one I could say that
each individual label had an 85% accuracy and that the issues came from matching lists.
-I don't know the accuracy for the individual labels under the OVR classifier.
-one major thing the OVR classifier has going for it is that it is infinitely faster. Like WAY faster.
-Another thing about the OVR classifier is that it could just be straight up suffering from a lack of training. 3000 samples is really nothing.
    -When I increased the training set size to 99%, increased overall accuracy to 28%. This could either be due to
    an increased amount of training having a good effect, or the size of the testing set is smaller too so less room for mistakes.
    -It's definitely the latter. 1% of the total set is only like 20 items.
    -Tried running it again on 95%. While there was a slight decrease in accuracy (expected), I was able to look over the results and found some correlations
    -Works best on single labels; works alright on labels that are often clustered together.
    -Going to save a training file on the OVR classifier, then run both classifiers over the entire dataset and compare results
    -While the OVR classifier has an overall better accuracy, I'm not sure about the individual labels
-Training has been finished for the OVRLR classifier, will try testing both now
-Wrote a class to import the pretrained classifier and do the classification, should work although untested

11/4 Notes:
-When don-E gets in, will need to ask what db Rahul moved all of the potentials to so I can know where to pull from for the classifier
-So goal for today: run the classifier over all the things.
-Okay, so the table is in Scholarship Universe; table name = ScholarshipUniverse.dbo.PotentialScholarships
-Going to make another table within Spiderman that will hold the classifier information; import the PotentialScholarshipId and Description, put those in
the new db with the classifier stuff
-Might be able to finally try and make the table; this worked, imported the scholarship id and the descriptions from the original table
-Now time to make class ClassifyPotentialScholarships and run the classifier
-Made the class, time to run
-lol I broke compy. Too much data for it, it can't do it
    -Going to try splitting up the data to run in parts, starting with halves, but I have a feeling that will still be too big; will try
    quarters next
-All of the grant forward stuff died. I am sad now.
-Splitting everything into halves seems to have solved the previous problem. Forgot to convert the tuples into strings but it's okay

11/9 Notes:
-Not really sure what to do today, for once
-Will start out by checking the status of the stuff I tried classifying last time
-Then ask don-E what to try next.
-Oooookay it looks like nothing got saved last time, so will have to rerun the classifier. Not sure if stuff didn't get saved because
it didn't go through, or if I didn't tell it to save it... from the looks of it, it just might not have gone through, because it should be calling
the save function. Will have to wait and see.
-Okay, it seems to be working nowish.
-Interestingly enough, the default classification seems to be Senior. When all else fails, it just defaults to Senior. Will have to clean that up a bit
-When don-E comes back from wherever he went, ask what to do next

11/13 Notes:
-I really really hate being sick
-wait for don-E to come in, figure out what major thing to do next
-In the meantime, check to see if there are any webscrapers that need to be built
-Need to rewrite unigoLeads class, they changed the website!
-having a lot of problems getting it to expand all of the things and then get the leads. It's trying to do both at the same time, which
ends up making it not expand out all of the scholarships so it only grabs the stuff on the first page. Its really stupid.
-Okay, there's something really up with unigo. Dunno why it's being bad but it's being bad. They might have put something on their site that is
blocking my webscraper
-Made a class to run all the webcrawlers while I'm gone. Godspeed, VPN. Godspeed.

11/20 Notes:
-Got some ideas from don-E about how I could improve my classifier.
-Some short term goals:
    -update the db insert class to allow an option to write to disk instead of inserting into db
    "Update the module that inserts sql into the database to also allow you to write it to disk.
    The file should be named with the site(or abbreviation) and/or date of some sort.
    You can do this by adding an option parameter saying desitination=database and then also do filesystem, maybe eventually to the web!
    If filesystem is chosen will need to provide a path also (make the default c:\crawlyjones)
    The file format should have a header row which tells the names of the parameters
    The fields should be delimitead by asci character 1 and the last field should be character asci character 2.
    Thus we should be able to go to a folder and slurp up all the files into 1 big file with all of the rows."

11/23 Notes:
-So far, for updating the data insert class, I've added in some optional parameters, which will let you choose filesystem or db, and an optional
parameter of where to put the file system
-Need to test that putting in these parameters hasn't broken the original function of the class

11/25 Notes:
-Need to actually do work today
-Test the SUDBConnect class, make sure original functionality still intact
-Wrote unit test for SUDBConnect, thought we already had tests for it but couldn't find them; verified that it still works
-Now need to add in similar functions to connect to a textfile and write in stuff
-Made a file in C:/ crawlyjones to store files
-Playing with unit tests. Found out that everytime you want to switch between writing and reading, you need to close and then reopen the file. Can't
do both at the same time. Will need to add that to all functions
-It's going well so far. Opens, reads, and writes to file. Yay

11/30 Notes:
-Need to figure out a way to insert rows into the given file.
    -Going to require columns and values, like the sql
    -If file is empty, then make a header row with the columns, then write the rows
-After that, need to figure out how to read in the rows. Don't want it to return the header column
    -Once figure out how to read in an entire row (return a list of all column values for that row), need to figure out
    how to return only values in a particular column
    -Might be able to do something like 'select id, name from blah' but it's a little pointless since it'll have to grab
    the whole row list anyway and then filter it out... and in order to do anything computational with it anyway it'll
    need to still assign one value at a time, so yeah. Might not need this after all

12/2 Notes:
-I really want to implement a similar functionality with the filesystem as we have with the current sql used with SUDBConnect.
-So I want to be able to have something to .getRows(whatKindOfRows) and something to insertUpdateOrDelete(whatKindofRows)
-Currently, in order to grab rows, SQL needs: tableName, whatToGetFromRow, whichRowsToLookAt
    -for example: 'select * from dbo.Tests where id='cat'' or something
    -So will have to have argument for fileName, and optional arguments of columnsToGet and a list of values to match in the column
    -The last one might be a total pain in the ass
-Just realized I need to have some sort of identity marker like in sql. Will have it work similarly to the default
incrementation of 1. Not sure how to store current values... could have a value that always gets stored at the end of the file, and everytime its
rewritten that value is read in, incremented by however much, and reappended to the end of the file... bleh

-Okay, completely nuke what I had before, because it turns out what I had in mind and what don-E wants me to make are completely
different
-Instead of having a single file for each website and each scholarship having its own entry, each website will have its own
directory and each scholarship will have its own file
-This is both a lot easier than what I was thinking, but different enough logically that it'll be hard
-Won't have to worry about identity stuff, which is awesome.
-If I do want to have an identity thing, can do it based on time created.
-So, in the Cerebro directory, a directory will be created for each user. In that directory, another directory will be created for the
given website. That website directory will store the individual files for the individual scholarships
-Need to figure out a way to write a file in a given place, as well as create a directory if it doesn't already exist.
-Filepath will be something like Cerebro\user\website\file
-The file names will be the name of the website, the url of the page, and the date the file was created/when the scholarship was mined
    -Everything created before now will not have a date associated with it, which is okay. Default date will be today (12/2/2015)
    -So it'll look something like website-url-YYYYMMDD.txt
-The url needs to be normalized so that it can go in the name of the document. There are a lot of illegal characters that need to be
removed and replaced.
    -Illegal characters: <, >, :, ", /, \, |, ?, *
    -Also need to remove periods (.) - will probably end up replacing periods with commas , unless they're particularly common in urls
    -Replace ? with (ques)

Replacement conventions:
- . = ((dot))
- < = ((less))
- > = ((great))
- : = ((col))
- " = ((dq))
- / = ((fs))
- \ = ((bs))
- | = ((pipe))
- ? = ((ques))
- * = ((ast))
- - = ((dash))

These should be okay to use in file names
-Convert url seems to be working perfectly fine, which is good


12/4 Notes:
-Need to figure out how to get column names from tables
- SELECT name FROM sys.columns WHERE OBJECT_ID = OBJECT_ID('dbo.Tests')
-Use this sql query, change the table name to whatever it needs to be

12/7 Notes:
-Need to figure out how to loop through rows, grab all the values of the row in a list, and then pass it to the function to write
that entry to disk
-okay, that ended up being 20x easier than I thought it would be, calling the row automatically returns the entire list
-Running into an issue with writing to file, sometimes it's running into undefined characters, so will have to figure
out how to filter out all of those things

12/9 Notes:
-Fixed the encoding issue by setting changing the program's encoding so that the output would be encoded correctly. Used:
# -*- coding: utf-8 -*-
import sys
values = [str(str(value).encode(sys.stdout.encoding, errors='replace')) for value in values]
-which basically encodes the values correctly when converting them to a string, instead of changing the encoding of the entire file
-this way it looks a lot prettier and will be easier to read back in.
-ugh, now getting issues with it not being able to make a file for some damn reason. Have no idea why. Probably has something
to do with the url
-now that I have written the existing stuff to the disk, need to make it so that future entries into the database will have a date
associated with them, which I can use to append to future files

-need to update webscrapers because everyone is always fucking changing things
-start updating Chegg AGAIN

12/16 Notes:
-still working on updating Chegg
-decided to get around the weird log in thing not working by implementing a while loop that keeps restarting the web
browser until it gets the right log in page. Is effective so far.
-now trying to get the number of matches so I can know how far to make the page scroll down before it's done
-After having too many issues where it's trying to get elements before they load, I have discovered that time.sleep() is literally
the best thing ever
-I think I broke the thing but I have no idea how wtf
-I think it's been sending it to the same damn page every single freaking time
-I actually don't know what broke it at all this time, checked the leads it's returning, they're giving unique values
-So something is going wrong with the insert thing
-realized what the issue was - the update statement didn't have a where statement attached to it, so it was just overwriting every line every time. Really dumb
-Chegg has been updated
-Will work on updating CollegeGreenLight Leads now - seems to be completely intact, so just need to run it and update the db
-collegegreenlightleads finished updating

12/17 Notes:
-Continue updating and running webscrapers, easy stuff today
-It's cold outside and that's not fucking okay
-Work on FastWebLeads; updated
-Work on Fatomei
-forgot to make sure that dates are inserted for the new entries, so had to rerun Fatomei/Fastweb/CollegeGreenLight
-update GoodCall; doesn't seem like much needs to be changed besides the insert program

12/18 Notes:
-Have phone interview today, meh
-Continue updating webscrapers
-don't know why some of the goodcall leads didn't insert a date properly, need to rerun, hopefully will force it to update things

1/4 Notes:
-Have no idea what to do today
-Thinking about condensing down the webscraping + opportunity classification + bad scholarship + pull out relevant info into
a single process rather than having to do one then the other and so on
-So will try reworking the latter processes so it can all be called by the Process class and then everything inserted at once
-Will start with Chegg just for somewhere to start
-General things to change:
    -Once get the leads from the Leads class, pull out the relevant info needed for opportunity classification
    -ClassifyFundingTypeKeywordBased.py
    -So far there's a RunFundingClassifierOn <blah> series of classes, would like to get rid of those
    -Those classes have been removed and rewritten into a series of unit tests
-So ClassifyFundingTypeKeywordBased works by taking a list of titles and info texts together, then outputs the predicted tags in a list
-So for the Process class, needs to pull out the title, the relevant pieces of the info text and concatenate them together
    -It will not need the GetDatabaseInfo classes because it is getting the information directly from the source before it's even
    inputted into the db
    -Fixed Chegg so far so that it calls the ClassifyFunding and pushes the results into the Insert class
-Now need to fix ClassifyBadScholarship, not sure how it will work
    -Will need to check if the given funding opportunity = Scholarship, if so then classify, if not then whatever
    -Edited the ClassifyBadScholarhip class to have default parameters of empty list so can call the class and use the
    classifyOpportunity function without needing to provide all that extra stuff
    -Added a function to Chegg that does this, returns the decision if there is one, otherwise returns None
    -Added in the parts to the Insert class, going to do a test run and see how it does

1/5 Notes:
-More steamlining, added functionality to write a file to disk as it inserts the lead into the database
-Had to add in functionality to SUDBConnect to delete old files if they are similar in name to the file it's trying to write now
-Basically works as an update system - delete the old file with a different date, write a new one with the new date
    -The idea is to make sure I don't have twenty million files for the same lead, either if I decide to run the program
    a million times in one day, or old files from before the update
    -Then added in a function to the Insert class which calls this functionality, grabs the row that was just inserted into the db, and
    then writes the file with that row
        -Decided to have the program insert then grab the row for the sake of consistency - I don't know exactly how I've organized the
        columns in the table, and I could move them around at any given point - I don't want to have to go in and fix my code
        every time I edit the table structure, so this will just grab the current format of the row
        -Time to test this out
-Chegg seems to be fully finished, now time to apply this to the other sites
-Added functionality to CollegeGreenLight leads, lets - nvm it broke
-Goddammit CGLL is broke, need to update webscraper
-So there's something wrong with the goddamn write file thing
    -Cause it's not writing the CollegeGreenLight stuff to disk for some reason
    -So need to figure out what's causing that because it's stupid
    -Okay so there's something wrong with every single one of those urls, dunno what tho
    -It's just really fucking stupid.
    -Windows has a cap on how long file names can be. GGWP.
        -Seriously, wow.
    -NUKE ALL THE SUBS. MAKE THEM ALL DOTS. FOR CHRISSAKE

1/7 Notes:
-Update FastWeb for streamlining, run that
-Update Fatomei next

1/8 Notes:
-Fatomei is having weird problems, trying to figure out why it's sometimes not wanting to write the files correctly.
-other than that, not much going on today
-Had to add a try/except statement to the InsertFatomeiLeads class; for some reason it's having a hard time finding a particular
entry even though it should have been added just before it's attempting to grab it
-Hopefully this will at least allow for the rest of the entries to be added

1/12 Notes:
-Update GoodCall
-Update seems to be okay, had to update the SQL table for this since it didn't have anything for Tag/BadScholarship
-Finally got GoodCall to run through, time to do the next one
-Update Iefa?
-I'd eventually like to update GrantForward, but I'm not sure if I can even still get to it...
-Need to update IefaLeads, realizing that Iefa hasn't been updated in a very long time...
-godbless the time module, taking care of cache issues since 2015

1/13 Notes:
-Not sure if IefaLeads paused over night when the VPN went down, or if its so fucking slow that it's still running. Holy balls.
-I would lol if this thing breaks and it really does take that long.
-Immediately noticed issue - damn thing must have logged out of Iefa over night and so it's not actually getting half of the important stuff
-So yeah, need to restart it. Lol.
-Some of these sites are very strange and don't load, I might want to consider implementing some sort of time out procedure or just hope that
it will eventually just load on its own
-Had an issue with CleanText apparently not removing a single quote. Not sure why it's being so weird... if that doesn't help, will use a try/except statement to get around it

1/15 Notes:
-So it turns out Iefa is stupid and not following proper url etiquette.
DO NOT PUT FUCKING SINGLE QUOTES IN A FUCKING URL HOLY SHIT WTF
-At least now I know what was breaking it
-Yay waiting 4 more hours to verify that it works

1/20 Notes:
-So it turns out that this thing really does run so slow that when I go home at night it doesn't finish before the VPN expires. RIP.
-Maybe it'll run through all the way today while I'm actually here and not throw dumb errors
-I need to do homework...
-Fucking holy fucking shit why does this keep happening
-Fucking internet died halfway through, logged out of Iefa, G fuckin G
-I really hope that this thing will finally run to completion, I really really don't want to have to deal with this again on Friday

1/22 Notes:
-Oh my fucking god if I can just get a single day where this thing can run through without any errors so that I don't have to
run it over night and guarantee that the VPN doesn't close, that would be great
-Yet another day of watching this run
-Aaaaaaand...
-omg it's working, lets see if it completes
-IT'S GOOD
-IT FINALLY FUCKING RAN THROUGH
HOLY SHIT YAY

Stuff for next week:
-Ken wants me to make a log system so we can keep track of when the webcrawlers are run, and how many entries they get
-Wants at least Website | Date | NumEntries
-Going to also add in data for how many are new entries and how many are updates
-Will need to rework the insert classes to return a value (maybe True/False) and then increment a count for updates/new in the Process classes
-Then when it's done have it save the thing to a new table, probably called dbo.CerebroWebcrawlerLogs

1/25 Notes:
-Trying to type without your index finger is really freaking annoying
-Make the log table that Ken wants, figure out how to increment the things
-I think I'd like some way to capture how many are done even if it breaks halfway through, but I dunno how... maybe put in a try/except statement
-Though if it's breaking due to the VPN closing then it's not gonna update the log anyway
-Maybe have a way to grab the current log row (dunno how?) and have that update every single time there's a success, but not sure if that's reasonable
-Made the table dbo.CerebroLogs
    -Columns are CerebroLogId, Website, Date, New, Updated, Total
-I might want to have the logging be done in its own class eventually, but for now will experiment using Chegg process class
-Put the logging in its own class. Don't have a way to increment the count as it goes, so it won't work right if the entire leads thing fails, but it's okay
-Will update some more stuff
    -Can confirm it's so far working as intended with the new/updates thing
-Need to add in a column to distinguish between total leads gathered and total leads in the table total
-Added function to CerebroLogs to get the total number of rows after everything has been done, should work fine now
    -Was able to go into the table with the existing logs and add in their total amounts, should be done automatically from now on
    -Will test to make sure it works as intended when run FastWeb
    -Can confirm works now
-So something's fucky with Fatomei
    -For some reason it's not listing anything as being an update (everything is registering as new)
    -And everything is listed as being updated on 1/8/2016
    -So wtf
    -must mean that something isn't being updated correctly...
    -I really have no idea, it's fucking weird
    -Will try rewriting the insert class since that seems to be where the issue is, but I don't really see it...

1/27 Notes:
-Figured out why Fatomei was being weird. Forgot to call the damn insertUpdateLead function that I had moved the executeables to.
    -The boolean only cares if the thing exists, not if its value is actually True or False. I should fix this.
    -Fatomei fixed now
-Need to update and run GoodCall
    -Goodcall finished, though it's having sort of a weird counting issue. I'm not going to worry about it for now, but I do think it's weird
    that it's not finding any new entries. I'll test it again in a week
-Afterwards still need to fix MastersInEducation, scholarships360, scholarsite, unigo, iefa
    -Starting Iefa now, not sure if it'll actually run through due to the vpn issues. Otherwise should be okay
    -Going to try restarting the vpn, maybe that will extend the time long enough for it to complete
-Then have other new websites to build crawlers for
-I really want to try getting the parsers implemented though. Might try that first
